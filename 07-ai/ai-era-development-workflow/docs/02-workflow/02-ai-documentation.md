# AIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ -- READMEã€APIä»•æ§˜ã€æŠ€è¡“æ–‡æ›¸ã®è‡ªå‹•åŒ–

> AIã‚’æ´»ç”¨ã—ã¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åŠ¹ç‡çš„ã«ç”Ÿæˆãƒ»ä¿å®ˆã™ã‚‹æ‰‹æ³•ã‚’å­¦ã³ã€READMEãƒ»APIä»•æ§˜æ›¸ãƒ»ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ–‡æ›¸ãƒ»å¤‰æ›´å±¥æ­´ã®è‡ªå‹•ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã—ã¦é–‹ç™ºè€…ä½“é¨“ï¼ˆDXï¼‰ã‚’å‘ä¸Šã•ã›ã‚‹

## ã“ã®ç« ã§å­¦ã¶ã“ã¨

1. **AIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆã®åŸºç›¤æŠ€è¡“** -- LLMã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰è§£æã€JSDoc/docstringã‹ã‚‰ã®ä»•æ§˜æ›¸ç”Ÿæˆã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç†è§£ã®ä»•çµ„ã¿
2. **å®Ÿè£…ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³** -- READMEè‡ªå‹•ç”Ÿæˆã€OpenAPIä»•æ§˜æ›¸ç”Ÿæˆã€CHANGELOGè‡ªå‹•ä½œæˆã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³ã®ç”Ÿæˆ
3. **å“è³ªç®¡ç†ã¨é‹ç”¨** -- ç”Ÿæˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã€CI/CDçµ±åˆã€é®®åº¦ç¶­æŒã®è‡ªå‹•åŒ–æˆ¦ç•¥

---

## 1. AIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆã®å…¨ä½“åƒ

### 1.1 ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```
AI ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

  ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰           AI å‡¦ç†               å‡ºåŠ›
  +----------+         +------------------+   +----------+
  | ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰|         | 1. ã‚³ãƒ¼ãƒ‰è§£æ     |   | README.md|
  | (*.ts,    | ------> | 2. æ§‹é€ ç†è§£       | ->| APIä»•æ§˜  |
  |  *.py)    |         | 3. æ–‡ç« ç”Ÿæˆ       |   | CHANGELOG|
  +----------+         | 4. ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ    |   +----------+
  +----------+         |                  |   +----------+
  | ã‚³ãƒ¡ãƒ³ãƒˆ   | ------> |                  | ->| ã‚¢ãƒ¼ã‚­   |
  | JSDoc     |         +------------------+   | ãƒ†ã‚¯ãƒãƒ£å›³|
  | docstring |                                +----------+
  +----------+
  +----------+
  | Gitå±¥æ­´   | ------> [å·®åˆ†åˆ†æ + è¦ç´„]  --> | å¤‰æ›´å±¥æ­´  |
  | PR/Issue  |                                +----------+
  +----------+
```

### 1.2 æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

```
AI ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ æŠ€è¡“ãƒãƒƒãƒ—

  LLM / AI ãƒ¢ãƒ‡ãƒ«
  â”œâ”€â”€ Claude            --- ã‚³ãƒ¼ãƒ‰ç†è§£ãƒ»æ–‡æ›¸ç”Ÿæˆï¼ˆé•·æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼‰
  â”œâ”€â”€ GPT-4             --- æ±ç”¨çš„ãªæ–‡æ›¸ç”Ÿæˆ
  â”œâ”€â”€ GitHub Copilot    --- ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
  â””â”€â”€ Gemini            --- å¤§è¦æ¨¡ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹è§£æ

  ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆãƒ„ãƒ¼ãƒ«
  â”œâ”€â”€ TypeDoc           --- TypeScript API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
  â”œâ”€â”€ Sphinx            --- Python ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
  â”œâ”€â”€ Swagger/OpenAPI   --- REST API ä»•æ§˜æ›¸
  â”œâ”€â”€ Storybook         --- UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚«ã‚¿ãƒ­ã‚°
  â””â”€â”€ Mermaid           --- ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ ç”Ÿæˆ

  CI/CD çµ±åˆ
  â”œâ”€â”€ GitHub Actions    --- è‡ªå‹•ç”Ÿæˆãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤
  â”œâ”€â”€ Pre-commit hooks  --- ã‚³ãƒŸãƒƒãƒˆæ™‚ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒã‚§ãƒƒã‚¯
  â””â”€â”€ Dependabot        --- ä¾å­˜é–¢ä¿‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°

  ãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚°
  â”œâ”€â”€ GitHub Pages      --- é™çš„ã‚µã‚¤ãƒˆå…¬é–‹
  â”œâ”€â”€ Notion API        --- ãƒãƒ¼ãƒ Wikié€£æº
  â””â”€â”€ Confluence API    --- ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºWiki
```

### 1.3 ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç¨®åˆ¥ã¨ç”Ÿæˆæˆ¦ç•¥

```
  ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç¨®åˆ¥         ç”Ÿæˆæ–¹æ³•              æ›´æ–°é »åº¦
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  README.md               AI + æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼     ãƒªãƒªãƒ¼ã‚¹ã”ã¨
  API ä»•æ§˜æ›¸ (OpenAPI)     ã‚³ãƒ¼ãƒ‰ã‹ã‚‰è‡ªå‹•ç”Ÿæˆ    ã‚³ãƒŸãƒƒãƒˆã”ã¨
  CHANGELOG               Git å±¥æ­´ã‹ã‚‰è‡ªå‹•ç”Ÿæˆ  ãƒªãƒªãƒ¼ã‚¹ã”ã¨
  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³          AI + æ‰‹å‹•èª¿æ•´        å¤§ããªå¤‰æ›´æ™‚
  ã‚³ãƒ¼ãƒ‰ã‚³ãƒ¡ãƒ³ãƒˆ           Copilot + æ‰‹å‹•       ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ™‚
  ã‚ªãƒ³ãƒœãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ–‡æ›¸      AI åˆç¨¿ + æ‰‹å‹•æ”¹å–„   å››åŠæœŸã”ã¨
  ADR (æ±ºå®šè¨˜éŒ²)           AI ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ + æ‰‹å‹• è¨­è¨ˆåˆ¤æ–­æ™‚
```

---

## 2. README è‡ªå‹•ç”Ÿæˆ

### 2.1 ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹è§£æã‹ã‚‰ README ã‚’ç”Ÿæˆ

```python
# AI ã«ã‚ˆã‚‹ README è‡ªå‹•ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
import os
import json
from pathlib import Path

class ReadmeGenerator:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚’è§£æã—ã¦ README ã‚’è‡ªå‹•ç”Ÿæˆ"""

    def __init__(self, project_root: str):
        self.root = Path(project_root)
        self.analysis = {}

    def analyze_project(self) -> dict:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚’è§£æ"""
        self.analysis = {
            "name": self._detect_project_name(),
            "language": self._detect_language(),
            "framework": self._detect_framework(),
            "dependencies": self._parse_dependencies(),
            "scripts": self._parse_scripts(),
            "directory_structure": self._get_directory_tree(),
            "entry_points": self._find_entry_points(),
            "env_vars": self._detect_env_vars(),
            "license": self._detect_license(),
        }
        return self.analysis

    def _detect_project_name(self) -> str:
        """package.json, pyproject.toml ç­‰ã‹ã‚‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‚’å–å¾—"""
        pkg_json = self.root / "package.json"
        if pkg_json.exists():
            data = json.loads(pkg_json.read_text())
            return data.get("name", self.root.name)

        pyproject = self.root / "pyproject.toml"
        if pyproject.exists():
            # TOML ãƒ‘ãƒ¼ã‚¹ã—ã¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‚’å–å¾—
            import tomllib
            data = tomllib.loads(pyproject.read_text())
            return data.get("project", {}).get("name", self.root.name)

        return self.root.name

    def _detect_language(self) -> list[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‹ã‚‰ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã‚’æ¨å®š"""
        extensions = {}
        for f in self.root.rglob("*"):
            if f.is_file() and not any(
                p in str(f) for p in ["node_modules", ".git", "__pycache__", "venv"]
            ):
                ext = f.suffix
                extensions[ext] = extensions.get(ext, 0) + 1

        lang_map = {
            ".ts": "TypeScript", ".tsx": "TypeScript",
            ".js": "JavaScript", ".jsx": "JavaScript",
            ".py": "Python", ".go": "Go", ".rs": "Rust",
            ".java": "Java", ".rb": "Ruby", ".swift": "Swift",
        }

        detected = []
        for ext, count in sorted(extensions.items(), key=lambda x: -x[1]):
            if ext in lang_map and lang_map[ext] not in detected:
                detected.append(lang_map[ext])
        return detected[:3]

    def _parse_dependencies(self) -> dict:
        """ä¾å­˜é–¢ä¿‚ã‚’è§£æ"""
        deps = {"runtime": [], "dev": []}
        pkg_json = self.root / "package.json"
        if pkg_json.exists():
            data = json.loads(pkg_json.read_text())
            deps["runtime"] = list(data.get("dependencies", {}).keys())
            deps["dev"] = list(data.get("devDependencies", {}).keys())
        return deps

    def _parse_scripts(self) -> dict:
        """å®Ÿè¡Œå¯èƒ½ãªã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’è§£æ"""
        pkg_json = self.root / "package.json"
        if pkg_json.exists():
            data = json.loads(pkg_json.read_text())
            return data.get("scripts", {})
        return {}

    def generate_readme(self) -> str:
        """è§£æçµæœã‹ã‚‰ README ã‚’ç”Ÿæˆ"""
        if not self.analysis:
            self.analyze_project()

        a = self.analysis
        sections = [
            f"# {a['name']}\n",
            self._generate_badges(a),
            self._generate_description(a),
            self._generate_quick_start(a),
            self._generate_installation(a),
            self._generate_usage(a),
            self._generate_project_structure(a),
            self._generate_scripts_section(a),
            self._generate_env_section(a),
            self._generate_contributing(),
            self._generate_license(a),
        ]
        return "\n".join(filter(None, sections))

    def _generate_quick_start(self, a: dict) -> str:
        """ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆ"""
        scripts = a.get("scripts", {})
        lines = ["## Quick Start\n", "```bash"]

        if "dev" in scripts:
            lines.extend([
                f"git clone <repository-url>",
                f"cd {a['name']}",
                "npm install",
                "npm run dev",
            ])
        elif a.get("language") and "Python" in a["language"]:
            lines.extend([
                f"git clone <repository-url>",
                f"cd {a['name']}",
                "pip install -e .",
            ])

        lines.append("```")
        return "\n".join(lines)
```

### 2.2 AI ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚ˆã‚‹ README æ”¹å–„

```python
# LLM ã‚’ä½¿ã£ãŸ README ã®å“è³ªæ”¹å–„
README_IMPROVEMENT_PROMPT = """
ã‚ãªãŸã¯å„ªç§€ãªãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
ä»¥ä¸‹ã®è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸ README ã‚’æ”¹å–„ã—ã¦ãã ã•ã„ã€‚

æ”¹å–„åŸºæº–:
1. æœ€åˆã®3è¡Œã§ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä¾¡å€¤ãŒä¼ã‚ã‚‹ã“ã¨
2. ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †ãŒéä¸è¶³ãªãã‚³ãƒ”ãƒšã§å‹•ãã“ã¨
3. ä¸»è¦ãªæ©Ÿèƒ½ãŒç®‡æ¡æ›¸ãã§ä¸€è¦§ã§ãã‚‹ã“ã¨
4. ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³æ–¹æ³•ãŒæ˜ç¢ºãªã“ã¨
5. ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ãŒæ˜è¨˜ã•ã‚Œã¦ã„ã‚‹ã“ã¨

è‡ªå‹•ç”Ÿæˆ README:
{auto_generated_readme}

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè§£æçµæœ:
{project_analysis}

æ”¹å–„ã•ã‚ŒãŸ README ã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""

def improve_readme_with_ai(auto_readme: str, analysis: dict, client) -> str:
    """AI ã§ README ã‚’æ”¹å–„"""
    prompt = README_IMPROVEMENT_PROMPT.format(
        auto_generated_readme=auto_readme,
        project_analysis=json.dumps(analysis, ensure_ascii=False, indent=2),
    )
    response = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=4096,
        messages=[{"role": "user", "content": prompt}],
    )
    return response.content[0].text
```

---

## 3. API ä»•æ§˜æ›¸ã®è‡ªå‹•ç”Ÿæˆ

### 3.1 ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ OpenAPI ä»•æ§˜æ›¸ã‚’ç”Ÿæˆ

```python
# FastAPI ã®å ´åˆ: è‡ªå‹•ã§ OpenAPI ä»•æ§˜ãŒç”Ÿæˆã•ã‚Œã‚‹
from fastapi import FastAPI, Query, Path, HTTPException
from pydantic import BaseModel, Field

app = FastAPI(
    title="ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç† API",
    description="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã® CRUD æ“ä½œã‚’æä¾›ã™ã‚‹ REST API",
    version="1.0.0",
    docs_url="/docs",           # Swagger UI
    redoc_url="/redoc",         # ReDoc
    openapi_url="/openapi.json", # OpenAPI JSON
)

class UserCreate(BaseModel):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    name: str = Field(..., min_length=1, max_length=100, description="ãƒ¦ãƒ¼ã‚¶ãƒ¼å")
    email: str = Field(..., description="ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹")
    role: str = Field(default="member", description="ãƒ­ãƒ¼ãƒ« (admin, member, viewer)")

    model_config = {
        "json_schema_extra": {
            "examples": [
                {"name": "ç”°ä¸­å¤ªéƒ", "email": "tanaka@example.com", "role": "member"}
            ]
        }
    }

class UserResponse(BaseModel):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    id: int = Field(..., description="ãƒ¦ãƒ¼ã‚¶ãƒ¼ID")
    name: str = Field(..., description="ãƒ¦ãƒ¼ã‚¶ãƒ¼å")
    email: str = Field(..., description="ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹")
    role: str = Field(..., description="ãƒ­ãƒ¼ãƒ«")

@app.post(
    "/users",
    response_model=UserResponse,
    status_code=201,
    summary="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ä½œæˆ",
    description="æ–°ã—ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ä½œæˆã—ã¾ã™ã€‚ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¯ä¸€æ„ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚",
    tags=["users"],
)
async def create_user(user: UserCreate):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æ–°è¦ä½œæˆã—ã¾ã™ã€‚

    - **name**: 1ã€œ100æ–‡å­—ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å
    - **email**: æœ‰åŠ¹ãªãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ (ä¸€æ„åˆ¶ç´„)
    - **role**: admin, member, viewer ã®ã„ãšã‚Œã‹
    """
    # å®Ÿè£…...
    return UserResponse(id=1, **user.model_dump())


@app.get(
    "/users/{user_id}",
    response_model=UserResponse,
    summary="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å–å¾—",
    tags=["users"],
)
async def get_user(
    user_id: int = Path(..., ge=1, description="ãƒ¦ãƒ¼ã‚¶ãƒ¼ID"),
):
    """æŒ‡å®šã•ã‚ŒãŸ ID ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚"""
    # å®Ÿè£…...
    pass
```

### 3.2 TypeScript ã®å‹å®šç¾©ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ

```typescript
// TypeDoc ç”¨ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚³ãƒ¡ãƒ³ãƒˆ
// TSDoc å½¢å¼ã§è¨˜è¿°ã™ã‚‹ã¨ TypeDoc ãŒè‡ªå‹•ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ

/**
 * ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹
 *
 * ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä½œæˆãƒ»å–å¾—ãƒ»æ›´æ–°ãƒ»å‰Šé™¤ã‚’æ‹…å½“ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹ã€‚
 * ãƒªãƒã‚¸ãƒˆãƒªãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹ã‚’æŠ½è±¡åŒ–ã—ã€
 * ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã‚’é›†ä¸­ç®¡ç†ã™ã‚‹ã€‚
 *
 * @example
 * ```typescript
 * const service = new UserService(userRepository);
 * const user = await service.createUser({
 *   name: "ç”°ä¸­å¤ªéƒ",
 *   email: "tanaka@example.com",
 * });
 * ```
 *
 * @see {@link UserRepository} ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹å±¤
 * @see {@link UserController} ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼å±¤
 */
export class UserService {
  /**
   * ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ä½œæˆã™ã‚‹
   *
   * @param input - ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
   * @returns ä½œæˆã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
   * @throws {DuplicateEmailError} ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãŒæ—¢ã«ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹å ´åˆ
   * @throws {ValidationError} å…¥åŠ›å€¤ãŒä¸æ­£ãªå ´åˆ
   */
  async createUser(input: CreateUserInput): Promise<User> {
    // å®Ÿè£…...
    return {} as User;
  }

  /**
   * ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æ¤œç´¢ã™ã‚‹
   *
   * @param query - æ¤œç´¢æ¡ä»¶
   * @param options - ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚ªãƒ—ã‚·ãƒ§ãƒ³
   * @returns ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ä»˜ããƒ¦ãƒ¼ã‚¶ãƒ¼ãƒªã‚¹ãƒˆ
   *
   * @example
   * ```typescript
   * const result = await service.searchUsers(
   *   { role: "admin" },
   *   { page: 1, limit: 20 }
   * );
   * console.log(result.total); // ç·ä»¶æ•°
   * console.log(result.items); // ãƒ¦ãƒ¼ã‚¶ãƒ¼é…åˆ—
   * ```
   */
  async searchUsers(
    query: SearchQuery,
    options: PaginationOptions
  ): Promise<PaginatedResult<User>> {
    // å®Ÿè£…...
    return {} as PaginatedResult<User>;
  }
}
```

### 3.3 docstring ã‹ã‚‰ã®è‡ªå‹•ç”Ÿæˆ

```python
# Python ã® docstring ã‹ã‚‰ AI ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ‹¡å……
import ast
import inspect

class DocstringEnhancer:
    """æ—¢å­˜ã® docstring ã‚’ AI ã§æ‹¡å……ã™ã‚‹ãƒ„ãƒ¼ãƒ«"""

    def extract_functions(self, source_code: str) -> list[dict]:
        """ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‹ã‚‰é–¢æ•°æƒ…å ±ã‚’æŠ½å‡º"""
        tree = ast.parse(source_code)
        functions = []

        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                func_info = {
                    "name": node.name,
                    "args": [arg.arg for arg in node.args.args],
                    "returns": ast.unparse(node.returns) if node.returns else None,
                    "docstring": ast.get_docstring(node),
                    "decorators": [ast.unparse(d) for d in node.decorator_list],
                    "lineno": node.lineno,
                }
                functions.append(func_info)

        return functions

    def generate_enhanced_docstring(self, func_info: dict, client) -> str:
        """AI ã§æ‹¡å……ã•ã‚ŒãŸ docstring ã‚’ç”Ÿæˆ"""
        prompt = f"""
ä»¥ä¸‹ã® Python é–¢æ•°ã«å¯¾ã—ã¦ã€Google ã‚¹ã‚¿ã‚¤ãƒ«ã® docstring ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

é–¢æ•°å: {func_info['name']}
å¼•æ•°: {func_info['args']}
æˆ»ã‚Šå€¤: {func_info['returns']}
æ—¢å­˜ã® docstring: {func_info['docstring'] or 'ãªã—'}

ä»¥ä¸‹ã‚’å«ã‚ã¦ãã ã•ã„:
1. é–¢æ•°ã®èª¬æ˜ï¼ˆ1-2æ–‡ï¼‰
2. Args ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆå„å¼•æ•°ã®å‹ã¨èª¬æ˜ï¼‰
3. Returns ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæˆ»ã‚Šå€¤ã®èª¬æ˜ï¼‰
4. Raises ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆç™ºç”Ÿã—ã†ã‚‹ä¾‹å¤–ï¼‰
5. Example ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆä½¿ç”¨ä¾‹ï¼‰
"""
        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=1024,
            messages=[{"role": "user", "content": prompt}],
        )
        return response.content[0].text
```

---

## 4. CHANGELOG è‡ªå‹•ç”Ÿæˆ

### 4.1 Git å±¥æ­´ã‹ã‚‰ã® CHANGELOG ç”Ÿæˆ

```python
# Conventional Commits ã‹ã‚‰ CHANGELOG ã‚’è‡ªå‹•ç”Ÿæˆ
import subprocess
import re
from datetime import datetime

class ChangelogGenerator:
    """Git ã‚³ãƒŸãƒƒãƒˆå±¥æ­´ã‹ã‚‰ CHANGELOG ã‚’è‡ªå‹•ç”Ÿæˆ"""

    COMMIT_TYPES = {
        "feat": "Features",
        "fix": "Bug Fixes",
        "docs": "Documentation",
        "style": "Styles",
        "refactor": "Code Refactoring",
        "perf": "Performance Improvements",
        "test": "Tests",
        "build": "Build System",
        "ci": "CI",
        "chore": "Chores",
    }

    # Conventional Commit ãƒ‘ã‚¿ãƒ¼ãƒ³
    PATTERN = re.compile(
        r"^(?P<type>feat|fix|docs|style|refactor|perf|test|build|ci|chore)"
        r"(?:\((?P<scope>[^)]+)\))?"
        r"(?P<breaking>!)?"
        r": (?P<description>.+)$"
    )

    def get_commits_since_tag(self, tag: str = None) -> list[dict]:
        """æŒ‡å®šã‚¿ã‚°ä»¥é™ã®ã‚³ãƒŸãƒƒãƒˆã‚’å–å¾—"""
        cmd = ["git", "log", "--pretty=format:%H|%s|%an|%aI"]
        if tag:
            cmd.append(f"{tag}..HEAD")

        result = subprocess.run(cmd, capture_output=True, text=True)
        commits = []

        for line in result.stdout.strip().split("\n"):
            if not line:
                continue
            parts = line.split("|", 3)
            if len(parts) == 4:
                hash_, subject, author, date = parts
                match = self.PATTERN.match(subject)
                if match:
                    commits.append({
                        "hash": hash_[:8],
                        "type": match.group("type"),
                        "scope": match.group("scope"),
                        "breaking": bool(match.group("breaking")),
                        "description": match.group("description"),
                        "author": author,
                        "date": date,
                    })

        return commits

    def generate_changelog(self, version: str, tag: str = None) -> str:
        """CHANGELOG ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚’ç”Ÿæˆ"""
        commits = self.get_commits_since_tag(tag)
        today = datetime.now().strftime("%Y-%m-%d")

        lines = [f"## [{version}] - {today}\n"]

        # Breaking Changes
        breaking = [c for c in commits if c["breaking"]]
        if breaking:
            lines.append("### BREAKING CHANGES\n")
            for c in breaking:
                scope = f"**{c['scope']}**: " if c["scope"] else ""
                lines.append(f"- {scope}{c['description']} ({c['hash']})")
            lines.append("")

        # ã‚¿ã‚¤ãƒ—åˆ¥ã«åˆ†é¡
        grouped = {}
        for c in commits:
            type_label = self.COMMIT_TYPES.get(c["type"], c["type"])
            grouped.setdefault(type_label, []).append(c)

        for type_label, type_commits in grouped.items():
            lines.append(f"### {type_label}\n")
            for c in type_commits:
                scope = f"**{c['scope']}**: " if c["scope"] else ""
                lines.append(f"- {scope}{c['description']} ({c['hash']})")
            lines.append("")

        return "\n".join(lines)


# ä½¿ç”¨ä¾‹
generator = ChangelogGenerator()
changelog = generator.generate_changelog("1.2.0", tag="v1.1.0")
print(changelog)
```

### 4.2 AI ã«ã‚ˆã‚‹ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆç”Ÿæˆ

```python
# Git å·®åˆ†ã‚’ AI ã§è¦ç´„ã—ã¦ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

RELEASE_NOTE_PROMPT = """
ä»¥ä¸‹ã® Git ã‚³ãƒŸãƒƒãƒˆä¸€è¦§ã‹ã‚‰ã€ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ã®ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã‚³ãƒŸãƒƒãƒˆä¸€è¦§:
{commits}

è¦ä»¶:
1. æŠ€è¡“çš„ãªè©³ç´°ã§ã¯ãªãã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦ã®ä¾¡å€¤ã‚’ä¼ãˆã‚‹
2. ã€Œæ–°æ©Ÿèƒ½ã€ã€Œæ”¹å–„ã€ã€Œä¿®æ­£ã€ã®ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡
3. å„é …ç›®ã¯1-2æ–‡ã§ç°¡æ½”ã«
4. æ—¥æœ¬èªã§è¨˜è¿°
"""

def generate_release_notes(commits: list[dict], client) -> str:
    """AI ã§ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    commits_text = "\n".join(
        f"- [{c['type']}] {c['description']}" for c in commits
    )
    prompt = RELEASE_NOTE_PROMPT.format(commits=commits_text)

    response = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=2048,
        messages=[{"role": "user", "content": prompt}],
    )
    return response.content[0].text
```

---

## 5. CI/CD çµ±åˆ

### 5.1 GitHub Actions ã§ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè‡ªå‹•ç”Ÿæˆ

```yaml
# .github/workflows/docs.yml
name: Generate Documentation

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  generate-docs:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # å…¨å±¥æ­´ã‚’å–å¾—ï¼ˆCHANGELOGç”Ÿæˆç”¨ï¼‰

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        run: npm ci

      # API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
      - name: Generate API docs
        run: npx typedoc --out docs/api src/

      # OpenAPI ä»•æ§˜æ›¸ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
      - name: Validate OpenAPI spec
        run: npx @redocly/cli lint openapi.yaml

      # README ã®é®®åº¦ãƒã‚§ãƒƒã‚¯
      - name: Check README freshness
        run: |
          python scripts/check_readme_freshness.py \
            --readme README.md \
            --package package.json \
            --threshold 30  # 30æ—¥ä»¥ä¸Šæ›´æ–°ãªã—ã§è­¦å‘Š

      # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ‡ãƒ—ãƒ­ã‚¤
      - name: Deploy docs
        if: github.ref == 'refs/heads/main'
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./docs

  check-docs-coverage:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã•ã‚ŒãŸé–¢æ•°ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸
      - name: Check documentation coverage
        run: |
          python scripts/doc_coverage.py \
            --src src/ \
            --min-coverage 80 \
            --report docs-coverage.json

      - name: Comment coverage on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const coverage = JSON.parse(fs.readFileSync('docs-coverage.json'));
            const body = `## Documentation Coverage\n\n` +
              `Coverage: **${coverage.percentage}%** (${coverage.documented}/${coverage.total})\n\n` +
              `${coverage.percentage >= 80 ? 'âœ…' : 'âš ï¸'} ` +
              `Minimum: 80%`;
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body,
            });
```

### 5.2 Pre-commit ãƒ•ãƒƒã‚¯ã§ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒã‚§ãƒƒã‚¯

```yaml
# .pre-commit-config.yaml
repos:
  - repo: local
    hooks:
      - id: check-docstrings
        name: Check docstrings
        entry: python scripts/check_docstrings.py
        language: python
        types: [python]
        args: ['--style', 'google', '--min-length', '10']

      - id: check-readme-links
        name: Check README links
        entry: python scripts/check_links.py
        language: python
        files: '\.md$'

      - id: generate-openapi
        name: Regenerate OpenAPI spec
        entry: python scripts/generate_openapi.py
        language: python
        files: '(routes|controllers|schemas)/.*\.py$'
        pass_filenames: false
```

---

## 6. æ¯”è¼ƒè¡¨

| ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç¨®åˆ¥ | è‡ªå‹•åŒ–åº¦ | AI æ´»ç”¨åŠ¹æœ | æ¨å¥¨ãƒ„ãƒ¼ãƒ« | æ›´æ–°é »åº¦ |
|----------------|:-------:|:--------:|:--------:|:------:|
| README | ä¸­ | é«˜ (åˆç¨¿ç”Ÿæˆ) | Claude + æ‰‹å‹• | ãƒªãƒªãƒ¼ã‚¹ã”ã¨ |
| API ä»•æ§˜æ›¸ (OpenAPI) | é«˜ | ä¸­ (è£œè¶³ç”Ÿæˆ) | FastAPI / TypeDoc | ã‚³ãƒŸãƒƒãƒˆã”ã¨ |
| CHANGELOG | é«˜ | é«˜ (è¦ç´„) | Conventional Commits | ãƒªãƒªãƒ¼ã‚¹ã”ã¨ |
| ã‚³ãƒ¼ãƒ‰ã‚³ãƒ¡ãƒ³ãƒˆ | ä¸­ | é«˜ (åˆç¨¿) | Copilot | ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ™‚ |
| ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³ | ä½ | ä¸­ (Mermaidç”Ÿæˆ) | Claude + Mermaid | è¨­è¨ˆå¤‰æ›´æ™‚ |
| ADR | ä½ | ä¸­ (ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ) | Claude + æ‰‹å‹• | æ±ºå®šæ™‚ |

| ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ | å“è³ª | é€Ÿåº¦ | ã‚³ã‚¹ãƒˆ | ä¿å®ˆæ€§ |
|-----------|:----:|:---:|:-----:|:-----:|
| å®Œå…¨æ‰‹å‹• | æœ€é«˜ | ä½ | é«˜ (äººä»¶è²») | ä½ (é™³è…åŒ–) |
| AI åˆç¨¿ + äººé–“ãƒ¬ãƒ“ãƒ¥ãƒ¼ | é«˜ | é«˜ | ä¸­ | é«˜ |
| ã‚³ãƒ¼ãƒ‰ã‹ã‚‰å®Œå…¨è‡ªå‹•ç”Ÿæˆ | ä¸­ | æœ€é«˜ | ä½ | æœ€é«˜ |
| AI ã®ã¿ (ãƒ¬ãƒ“ãƒ¥ãƒ¼ãªã—) | ä½ã€œä¸­ | æœ€é«˜ | æœ€ä½ | ä¸­ |

---

## 7. ã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³

### ã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³ 1: AI ç”Ÿæˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç„¡æ¤œè¨¼ã§å…¬é–‹

```
BAD:
  AI ãŒç”Ÿæˆã—ãŸ API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãã®ã¾ã¾å…¬é–‹
  â†’ å®Ÿè£…ã¨ç•°ãªã‚‹è¨˜è¿°ã€å­˜åœ¨ã—ãªã„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®è¨˜è¼‰
  â†’ ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆAI ã®å¹»è¦šï¼‰ã«ã‚ˆã‚‹èª¤æƒ…å ±
  â†’ åˆ©ç”¨è€…ãŒèª¤ã£ãŸæƒ…å ±ã«åŸºã¥ã„ã¦å®Ÿè£…ã—ã€éšœå®³ç™ºç”Ÿ

GOOD:
  1. AI ã§åˆç¨¿ã‚’ç”Ÿæˆï¼ˆé€Ÿåº¦å‘ä¸Šï¼‰
  2. å®Ÿéš›ã®ã‚³ãƒ¼ãƒ‰ã¨ã®æ•´åˆæ€§ã‚’è‡ªå‹•ãƒã‚§ãƒƒã‚¯
  3. ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ©ã‚¤ã‚¿ãƒ¼ã¾ãŸã¯é–‹ç™ºè€…ãŒãƒ¬ãƒ“ãƒ¥ãƒ¼
  4. ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã¯å®Ÿéš›ã«å‹•ä½œç¢ºèª
  5. CI ã§ OpenAPI spec ã¨å®Ÿè£…ã®ä¸æ•´åˆã‚’æ¤œå‡º
```

### ã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³ 2: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®é®®åº¦ç®¡ç†ã‚’æ€ ã‚‹

```
BAD:
  ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–‹å§‹æ™‚ã«ç«‹æ´¾ãª README ã‚’ä½œæˆ
  â†’ åŠå¹´å¾Œã€ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †ãŒå¤ãã¦å‹•ã‹ãªã„
  â†’ API ä»•æ§˜æ›¸ãŒå®Ÿè£…ã¨ä¹–é›¢
  â†’ æ–°ãƒ¡ãƒ³ãƒãƒ¼ãŒèª¤ã£ãŸæƒ…å ±ã§ãƒãƒã‚‹

GOOD:
  - CI ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æœ€çµ‚æ›´æ–°æ—¥ã‚’ãƒã‚§ãƒƒã‚¯
  - package.json ã®å¤‰æ›´æ™‚ã« README ã®ä¾å­˜é–¢ä¿‚ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è‡ªå‹•æ›´æ–°
  - PR ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«ã€Œãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°ã®è¦å¦ã€ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹
  - æœˆæ¬¡ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé®®åº¦ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
  - ã€Œdocsã€ãƒ©ãƒ™ãƒ«ã® Issue ã‚’è‡ªå‹•ä½œæˆ
```

### ã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³ 3: å…¨ã¦ã‚’1ã¤ã® README ã«è©°ã‚è¾¼ã‚€

```
BAD:
  README.md ãŒ 2000 è¡Œè¶…
  â†’ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †ã€API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£èª¬æ˜ã€
     ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãŒå…¨ã¦1ãƒ•ã‚¡ã‚¤ãƒ«
  â†’ å¿…è¦ãªæƒ…å ±ã‚’è¦‹ã¤ã‘ã‚‰ã‚Œãªã„

GOOD:
  README.md ã¯ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼ˆ100è¡Œä»¥å†…ï¼‰ã«ã¨ã©ã‚ã‚‹:
  - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦ï¼ˆ3è¡Œï¼‰
  - ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆ10è¡Œï¼‰
  - ä¸»è¦æ©Ÿèƒ½ä¸€è¦§
  - è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¸ã®ãƒªãƒ³ã‚¯é›†
    - docs/setup.md  --- ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †
    - docs/api.md    --- API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹
    - docs/architecture.md --- è¨­è¨ˆæ–‡æ›¸
```

---

## 8. FAQ

### Q1. AI ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã™ã‚‹éš›ã®å“è³ªã‚’ç¢ºä¿ã™ã‚‹ã«ã¯ï¼Ÿ

**A.** (1) **ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æä¾›**: ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã€ãƒ†ã‚¹ãƒˆã€æ—¢å­˜ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã¾ã¨ã‚ã¦ AI ã«æ¸¡ã™ã“ã¨ã§ç²¾åº¦ãŒå‘ä¸Šã™ã‚‹ã€‚(2) **ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®æ´»ç”¨**: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å®šç¾©ã—ã€AI ã«å¾“ã‚ã›ã‚‹ã€‚(3) **è‡ªå‹•æ¤œè¨¼**: ç”Ÿæˆã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’ CI ã§å®Ÿè¡Œã—ã€å‹•ä½œã‚’ç¢ºèªã™ã‚‹ã€‚(4) **æ®µéšçš„å°å…¥**: ã¾ãšå†…éƒ¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆADRã€è¨­è¨ˆãƒ¡ãƒ¢ï¼‰ã‹ã‚‰å§‹ã‚ã€ç²¾åº¦ã‚’ç¢ºèªã—ã¦ã‹ã‚‰å¤–éƒ¨å‘ã‘ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å±•é–‹ã™ã‚‹ã€‚AI ç”Ÿæˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å“è³ªã¯ã€å…¥åŠ›ã®å“è³ªã«å¤§ããä¾å­˜ã™ã‚‹ã€‚

### Q2. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è‡ªå‹•ç”Ÿæˆã‚’ CI ã«çµ„ã¿è¾¼ã‚€ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã¯ï¼Ÿ

**A.** (1) **PR æ™‚ã®ãƒã‚§ãƒƒã‚¯**: docstring ã‚«ãƒãƒ¬ãƒƒã‚¸ã€OpenAPI æ•´åˆæ€§ã€ãƒªãƒ³ã‚¯åˆ‡ã‚Œæ¤œå‡ºã‚’ PR ã®ãƒã‚§ãƒƒã‚¯é …ç›®ã«å«ã‚ã‚‹ã€‚(2) **ãƒãƒ¼ã‚¸æ™‚ã®ç”Ÿæˆ**: main ãƒ–ãƒ©ãƒ³ãƒã¸ã®ãƒãƒ¼ã‚¸æ™‚ã« API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è‡ªå‹•å†ç”Ÿæˆãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã€‚(3) **ãƒªãƒªãƒ¼ã‚¹æ™‚ã® CHANGELOG**: ã‚¿ã‚°ä½œæˆæ™‚ã« Conventional Commits ã‹ã‚‰ CHANGELOG ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹ã€‚(4) **å®šæœŸãƒ¬ãƒãƒ¼ãƒˆ**: é€±æ¬¡ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé®®åº¦ãƒ¬ãƒãƒ¼ãƒˆã‚’ Slack ã«é€šçŸ¥ã™ã‚‹ã€‚æ®µéšçš„ã«è‡ªå‹•åŒ–ç¯„å›²ã‚’åºƒã’ã‚‹ã®ãŒç¾å®Ÿçš„ã€‚

### Q3. å°è¦æ¨¡ãƒãƒ¼ãƒ ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†ã‚’åŠ¹ç‡åŒ–ã™ã‚‹ã«ã¯ï¼Ÿ

**A.** (1) **README é§†å‹•é–‹ç™º**: ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å‰ã« README ã‚’æ›¸ãã€ãã‚Œã‚’ä»•æ§˜ã¨ã—ã¦é–‹ç™ºã™ã‚‹ã€‚AI ã§åˆç¨¿ã‚’ç”Ÿæˆã™ã‚‹ã¨é«˜é€Ÿã€‚(2) **Docs as Code**: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ãƒªãƒã‚¸ãƒˆãƒªã§ç®¡ç†ã—ã€PR ã§ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹ã€‚(3) **ADR ã®æ´»ç”¨**: è¨­è¨ˆåˆ¤æ–­ã‚’ Architecture Decision Records ã¨ã—ã¦è¨˜éŒ²ã—ã€ã€Œãªãœã“ã®è¨­è¨ˆã«ã—ãŸã‹ã€ã‚’æ®‹ã™ã€‚(4) **è‡ªå‹•åŒ–ã®å„ªå…ˆé †ä½**: ã¾ãš CHANGELOG ã®è‡ªå‹•ç”Ÿæˆã€æ¬¡ã« API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€æœ€å¾Œã« README ã®é®®åº¦ç®¡ç†ã®é †ã§å°å…¥ã™ã‚‹ã€‚å°è¦æ¨¡ãƒãƒ¼ãƒ ã“ãè‡ªå‹•åŒ–ã®åŠ¹æœãŒå¤§ãã„ã€‚

---

## 9. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è‡ªå‹•ç”Ÿæˆ

### 9.1 ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‹ã‚‰Mermaidãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ ã‚’ç”Ÿæˆ

```python
# ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’è§£æã—ã¦ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ ã‚’è‡ªå‹•ç”Ÿæˆ

import ast
from pathlib import Path
from typing import NamedTuple

class DependencyInfo(NamedTuple):
    source: str
    target: str
    relationship: str  # "imports", "inherits", "uses"

class ArchitectureDiagramGenerator:
    """ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‹ã‚‰Mermaidãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ ã‚’è‡ªå‹•ç”Ÿæˆ"""

    def __init__(self, project_root: str):
        self.root = Path(project_root)
        self.dependencies: list[DependencyInfo] = []
        self.modules: dict[str, dict] = {}

    def analyze_python_project(self) -> dict:
        """Pythonãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä¾å­˜é–¢ä¿‚ã‚’è§£æ"""
        for py_file in self.root.rglob("*.py"):
            if any(skip in str(py_file) for skip in [
                "__pycache__", "node_modules", ".venv", "venv", "test"
            ]):
                continue

            relative_path = py_file.relative_to(self.root)
            module_name = str(relative_path).replace("/", ".").replace(".py", "")

            try:
                tree = ast.parse(py_file.read_text())
                imports = self._extract_imports(tree)
                classes = self._extract_classes(tree)
                functions = self._extract_functions(tree)

                self.modules[module_name] = {
                    "path": str(relative_path),
                    "imports": imports,
                    "classes": classes,
                    "functions": functions,
                    "loc": len(py_file.read_text().splitlines()),
                }

                for imp in imports:
                    self.dependencies.append(DependencyInfo(
                        source=module_name,
                        target=imp,
                        relationship="imports",
                    ))
            except SyntaxError:
                pass

        return {
            "modules": self.modules,
            "dependencies": self.dependencies,
        }

    def generate_component_diagram(self) -> str:
        """ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå›³ã‚’Mermaidå½¢å¼ã§ç”Ÿæˆ"""
        lines = ["graph TD"]

        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        layers = self._detect_layers()

        for layer_name, modules in layers.items():
            lines.append(f"    subgraph {layer_name}")
            for mod in modules:
                class_count = len(self.modules.get(mod, {}).get("classes", []))
                func_count = len(self.modules.get(mod, {}).get("functions", []))
                label = f"{mod.split('.')[-1]}\\n({class_count}classes, {func_count}funcs)"
                lines.append(f'        {mod.replace(".", "_")}["{label}"]')
            lines.append("    end")

        # ä¾å­˜é–¢ä¿‚ã®çŸ¢å°
        for dep in self.dependencies:
            if dep.target in self.modules:
                source_id = dep.source.replace(".", "_")
                target_id = dep.target.replace(".", "_")
                lines.append(f"    {source_id} --> {target_id}")

        return "\n".join(lines)

    def generate_class_diagram(self) -> str:
        """ã‚¯ãƒ©ã‚¹å›³ã‚’Mermaidå½¢å¼ã§ç”Ÿæˆ"""
        lines = ["classDiagram"]

        for mod_name, mod_info in self.modules.items():
            for cls in mod_info.get("classes", []):
                cls_name = cls["name"]
                lines.append(f"    class {cls_name} {{")
                for method in cls.get("methods", []):
                    visibility = "+" if not method.startswith("_") else "-"
                    lines.append(f"        {visibility}{method}()")
                lines.append("    }")

                # ç¶™æ‰¿é–¢ä¿‚
                for base in cls.get("bases", []):
                    lines.append(f"    {base} <|-- {cls_name}")

        return "\n".join(lines)

    def generate_ai_prompt(self) -> str:
        """AI ã«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è§£èª¬ã‚’ä¾é ¼ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ"""
        return f"""
ä»¥ä¸‹ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚’åˆ†æã—ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

## ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä¸€è¦§ï¼ˆ{len(self.modules)}ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼‰
{self._format_module_summary()}

## ä¾å­˜é–¢ä¿‚ï¼ˆ{len(self.dependencies)}ä»¶ï¼‰
{self._format_dependency_summary()}

## å‡ºåŠ›å½¢å¼
1. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦ï¼ˆ3-5æ–‡ï¼‰
2. ãƒ¬ã‚¤ãƒ¤ãƒ¼æ§‹æˆã®èª¬æ˜
3. ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®è²¬å‹™
4. ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã®èª¬æ˜
5. æ”¹å–„ææ¡ˆï¼ˆã‚ã‚Œã°ï¼‰
"""

    def _detect_layers(self) -> dict[str, list[str]]:
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åã‹ã‚‰ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’è‡ªå‹•æ¤œå‡º"""
        layer_keywords = {
            "Presentation": ["controller", "handler", "view", "route", "api"],
            "Application": ["service", "usecase", "command", "query"],
            "Domain": ["model", "entity", "domain", "aggregate"],
            "Infrastructure": ["repository", "adapter", "client", "db"],
        }
        layers: dict[str, list[str]] = {}
        for mod_name in self.modules:
            mod_lower = mod_name.lower()
            placed = False
            for layer, keywords in layer_keywords.items():
                if any(kw in mod_lower for kw in keywords):
                    layers.setdefault(layer, []).append(mod_name)
                    placed = True
                    break
            if not placed:
                layers.setdefault("Other", []).append(mod_name)
        return layers

    def _extract_imports(self, tree: ast.AST) -> list[str]:
        imports = []
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append(alias.name)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    imports.append(node.module)
        return imports

    def _extract_classes(self, tree: ast.AST) -> list[dict]:
        classes = []
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                methods = [
                    n.name for n in node.body
                    if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef))
                ]
                bases = [ast.unparse(b) for b in node.bases]
                classes.append({
                    "name": node.name,
                    "methods": methods,
                    "bases": bases,
                })
        return classes

    def _extract_functions(self, tree: ast.AST) -> list[str]:
        return [
            node.name for node in ast.iter_child_nodes(tree)
            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef))
        ]

    def _format_module_summary(self) -> str:
        return "\n".join(
            f"- {name}: {info['loc']}è¡Œ, "
            f"ã‚¯ãƒ©ã‚¹{len(info['classes'])}å€‹, é–¢æ•°{len(info['functions'])}å€‹"
            for name, info in sorted(self.modules.items())
        )

    def _format_dependency_summary(self) -> str:
        return "\n".join(
            f"- {d.source} â†’ {d.target} ({d.relationship})"
            for d in self.dependencies[:20]
        )
```

### 9.2 ADRï¼ˆArchitecture Decision Recordsï¼‰ã®è‡ªå‹•ç”Ÿæˆ

```python
# AI ã§ ADR ã®ãƒ‰ãƒ©ãƒ•ãƒˆã‚’è‡ªå‹•ç”Ÿæˆ

ADR_TEMPLATE_PROMPT = """
ä»¥ä¸‹ã®è¨­è¨ˆåˆ¤æ–­ã«ã¤ã„ã¦ã€ADR (Architecture Decision Record) ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

## è¨­è¨ˆåˆ¤æ–­ã®æ¦‚è¦
{decision_summary}

## ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
{context}

## æ¤œè¨ã—ãŸé¸æŠè‚¢
{options}

## ADR ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ï¼‰

# ADR-{adr_number}: {title}

## ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
ææ¡ˆä¸­ / æ‰¿èªæ¸ˆã¿ / å»ƒæ­¢

## ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
ï¼ˆã“ã®æ±ºå®šãŒå¿…è¦ã«ãªã£ãŸèƒŒæ™¯ãƒ»èª²é¡Œã‚’è¨˜è¿°ï¼‰

## æ±ºå®š
ï¼ˆæ¡ç”¨ã—ãŸè§£æ±ºç­–ã‚’å…·ä½“çš„ã«è¨˜è¿°ï¼‰

## æ¤œè¨ã—ãŸé¸æŠè‚¢
### é¸æŠè‚¢A: ...
- åˆ©ç‚¹: ...
- æ¬ ç‚¹: ...

### é¸æŠè‚¢B: ...
- åˆ©ç‚¹: ...
- æ¬ ç‚¹: ...

### é¸æŠè‚¢C: ...
- åˆ©ç‚¹: ...
- æ¬ ç‚¹: ...

## æ±ºå®šã®æ ¹æ‹ 
ï¼ˆãªãœã“ã®é¸æŠè‚¢ã‚’é¸ã‚“ã ã‹ã®ç†ç”±ã‚’è¨˜è¿°ï¼‰

## å½±éŸ¿
- è‰¯ã„å½±éŸ¿: ...
- ãƒªã‚¹ã‚¯: ...
- ç§»è¡Œè¨ˆç”»: ...

## å‚è€ƒæƒ…å ±
- é–¢é€£ã™ã‚‹ADR: ...
- å‚è€ƒæ–‡çŒ®: ...
"""

class ADRGenerator:
    """ADRã®è‡ªå‹•ç”Ÿæˆã¨ç®¡ç†"""

    def __init__(self, adr_dir: str = "docs/adr"):
        self.adr_dir = Path(adr_dir)
        self.adr_dir.mkdir(parents=True, exist_ok=True)

    def get_next_number(self) -> int:
        """æ¬¡ã®ADRç•ªå·ã‚’å–å¾—"""
        existing = list(self.adr_dir.glob("*.md"))
        if not existing:
            return 1
        numbers = []
        for f in existing:
            try:
                num = int(f.stem.split("-")[0])
                numbers.append(num)
            except (ValueError, IndexError):
                pass
        return max(numbers, default=0) + 1

    def generate_adr(self, decision: dict, client) -> str:
        """AIã§ADRã®ãƒ‰ãƒ©ãƒ•ãƒˆã‚’ç”Ÿæˆ"""
        adr_number = self.get_next_number()
        prompt = ADR_TEMPLATE_PROMPT.format(
            adr_number=adr_number,
            title=decision.get("title", ""),
            decision_summary=decision.get("summary", ""),
            context=decision.get("context", ""),
            options=decision.get("options", ""),
        )

        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=4096,
            messages=[{"role": "user", "content": prompt}],
        )

        adr_content = response.content[0].text
        filename = f"{adr_number:04d}-{decision['title'].lower().replace(' ', '-')}.md"
        filepath = self.adr_dir / filename
        filepath.write_text(adr_content)

        return str(filepath)
```

---

## 10. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé®®åº¦ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

### 10.1 è‡ªå‹•é®®åº¦ãƒã‚§ãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ 

```python
# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®é®®åº¦ã‚’è‡ªå‹•çš„ã«ç›£è¦–ã—ã€é™³è…åŒ–ã‚’é˜²æ­¢ã™ã‚‹

import subprocess
from datetime import datetime, timedelta
from dataclasses import dataclass, field

@dataclass
class DocFreshnessReport:
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé®®åº¦ãƒ¬ãƒãƒ¼ãƒˆ"""
    file_path: str
    last_modified: datetime
    related_code_modified: datetime
    days_stale: int
    staleness_level: str  # "fresh", "aging", "stale", "critical"
    related_changes: list[str] = field(default_factory=list)

class DocFreshnessMonitor:
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®é®®åº¦ã‚’ç›£è¦–ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ """

    STALENESS_THRESHOLDS = {
        "README.md": 30,           # 30æ—¥
        "CONTRIBUTING.md": 90,     # 90æ—¥
        "docs/api/": 14,           # 14æ—¥
        "docs/architecture/": 60,  # 60æ—¥
        "CHANGELOG.md": 7,         # 7æ—¥ï¼ˆãƒªãƒªãƒ¼ã‚¹ã‚µã‚¤ã‚¯ãƒ«ã«ä¾å­˜ï¼‰
    }

    def check_freshness(self, doc_path: str) -> DocFreshnessReport:
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®é®®åº¦ã‚’ãƒã‚§ãƒƒã‚¯"""
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æœ€çµ‚æ›´æ–°æ—¥
        doc_modified = self._get_last_modified(doc_path)

        # é–¢é€£ã‚³ãƒ¼ãƒ‰ã®æœ€çµ‚æ›´æ–°æ—¥
        related_code = self._find_related_code(doc_path)
        code_modified = max(
            (self._get_last_modified(f) for f in related_code),
            default=doc_modified,
        )

        # é®®åº¦ã®è¨ˆç®—
        days_stale = (datetime.now() - doc_modified).days
        code_days_ahead = (code_modified - doc_modified).days

        # é®®åº¦ãƒ¬ãƒ™ãƒ«ã®åˆ¤å®š
        threshold = self._get_threshold(doc_path)
        if code_days_ahead > threshold:
            staleness_level = "critical"
        elif code_days_ahead > threshold // 2:
            staleness_level = "stale"
        elif days_stale > threshold:
            staleness_level = "aging"
        else:
            staleness_level = "fresh"

        # é–¢é€£ã™ã‚‹å¤‰æ›´ã®å–å¾—
        related_changes = self._get_changes_since(doc_modified, related_code)

        return DocFreshnessReport(
            file_path=doc_path,
            last_modified=doc_modified,
            related_code_modified=code_modified,
            days_stale=days_stale,
            staleness_level=staleness_level,
            related_changes=related_changes,
        )

    def generate_freshness_report(self, doc_paths: list[str]) -> str:
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé®®åº¦ã®å…¨ä½“ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        reports = [self.check_freshness(path) for path in doc_paths]

        critical = [r for r in reports if r.staleness_level == "critical"]
        stale = [r for r in reports if r.staleness_level == "stale"]
        aging = [r for r in reports if r.staleness_level == "aging"]
        fresh = [r for r in reports if r.staleness_level == "fresh"]

        output = "# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé®®åº¦ãƒ¬ãƒãƒ¼ãƒˆ\n\n"
        output += f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().isoformat()}\n\n"
        output += f"## ã‚µãƒãƒªãƒ¼\n"
        output += f"- æœ€æ–°: {len(fresh)}ä»¶\n"
        output += f"- çµŒå¹´: {len(aging)}ä»¶\n"
        output += f"- è¦æ›´æ–°: {len(stale)}ä»¶\n"
        output += f"- ç·Šæ€¥: {len(critical)}ä»¶\n\n"

        if critical:
            output += "## ç·Šæ€¥å¯¾å¿œãŒå¿…è¦ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ\n\n"
            for r in critical:
                output += f"- **{r.file_path}**: "
                output += f"{r.days_stale}æ—¥å‰ã«æ›´æ–°ã€"
                output += f"é–¢é€£ã‚³ãƒ¼ãƒ‰ã¯{(r.related_code_modified - r.last_modified).days}æ—¥å…ˆè¡Œ\n"
                for change in r.related_changes[:3]:
                    output += f"  - {change}\n"

        return output

    def _get_last_modified(self, file_path: str) -> datetime:
        """Gitã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€çµ‚æ›´æ–°æ—¥ã‚’å–å¾—"""
        try:
            result = subprocess.run(
                ["git", "log", "-1", "--format=%aI", "--", file_path],
                capture_output=True, text=True, timeout=5,
            )
            if result.stdout.strip():
                return datetime.fromisoformat(result.stdout.strip())
        except Exception:
            pass
        return datetime.now()

    def _get_threshold(self, doc_path: str) -> int:
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ‘ã‚¹ã«å¿œã˜ãŸé–¾å€¤ã‚’è¿”ã™"""
        for pattern, threshold in self.STALENESS_THRESHOLDS.items():
            if pattern in doc_path:
                return threshold
        return 30  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ30æ—¥

    def _find_related_code(self, doc_path: str) -> list[str]:
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«é–¢é€£ã™ã‚‹ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¨å®š"""
        related = []
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ã‚’è§£æ
        # ä¾‹: README.md â†’ src/ é…ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«
        # ä¾‹: docs/api/users.md â†’ src/controllers/users.ts
        return related

    def _get_changes_since(self, since: datetime,
                           files: list[str]) -> list[str]:
        """æŒ‡å®šæ—¥æ™‚ä»¥é™ã®å¤‰æ›´ã‚’å–å¾—"""
        changes = []
        for f in files:
            try:
                result = subprocess.run(
                    ["git", "log", "--oneline",
                     f"--since={since.isoformat()}", "--", f],
                    capture_output=True, text=True, timeout=5,
                )
                if result.stdout.strip():
                    changes.extend(result.stdout.strip().split("\n"))
            except Exception:
                pass
        return changes
```

### 10.2 Slacké€šçŸ¥ã¨ã®çµ±åˆ

```python
# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé®®åº¦ãƒ¬ãƒãƒ¼ãƒˆã‚’Slackã«è‡ªå‹•é€šçŸ¥

class DocFreshnessNotifier:
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé®®åº¦ã‚’Slackã«é€šçŸ¥"""

    def __init__(self, webhook_url: str):
        self.webhook_url = webhook_url

    def notify_stale_docs(self, reports: list[DocFreshnessReport]) -> None:
        """é™³è…åŒ–ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’Slackã«é€šçŸ¥"""
        import requests

        stale_docs = [r for r in reports if r.staleness_level in ("stale", "critical")]
        if not stale_docs:
            return

        blocks = [
            {
                "type": "header",
                "text": {
                    "type": "plain_text",
                    "text": f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé®®åº¦ã‚¢ãƒ©ãƒ¼ãƒˆï¼ˆ{len(stale_docs)}ä»¶ï¼‰",
                }
            },
        ]

        for doc in stale_docs[:5]:
            emoji = "ğŸ”´" if doc.staleness_level == "critical" else "ğŸŸ¡"
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": (
                        f"{emoji} *{doc.file_path}*\n"
                        f"æœ€çµ‚æ›´æ–°: {doc.days_stale}æ—¥å‰ | "
                        f"é–¢é€£ã‚³ãƒ¼ãƒ‰ã¨ã®å·®: "
                        f"{(doc.related_code_modified - doc.last_modified).days}æ—¥"
                    ),
                }
            })

        payload = {"blocks": blocks}
        requests.post(self.webhook_url, json=payload)
```

---

## ã¾ã¨ã‚

| é …ç›® | ãƒã‚¤ãƒ³ãƒˆ |
|------|---------|
| README ç”Ÿæˆ | ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚’è‡ªå‹•è§£æ â†’ AI ã§åˆç¨¿ç”Ÿæˆ â†’ äººé–“ãŒãƒ¬ãƒ“ãƒ¥ãƒ¼ |
| API ä»•æ§˜æ›¸ | FastAPI/TypeDoc ã§è‡ªå‹•ç”Ÿæˆã€‚Pydantic ã®å‹æƒ…å ±ãŒãã®ã¾ã¾ä»•æ§˜ã« |
| CHANGELOG | Conventional Commits + è‡ªå‹•ç”Ÿæˆã€‚AI ã§ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã‚’è¦ç´„ |
| CI/CD çµ±åˆ | ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ã€é®®åº¦ãƒã‚§ãƒƒã‚¯ã€è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤ã‚’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«çµ„ã¿è¾¼ã‚€ |
| å“è³ªç®¡ç† | AI ç”Ÿæˆã¯åˆç¨¿ã€‚å¿…ãšäººé–“ãŒãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã¯å‹•ä½œç¢ºèª |
| é®®åº¦ç¶­æŒ | è‡ªå‹•ãƒã‚§ãƒƒã‚¯ + PR ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ + æœˆæ¬¡ãƒ¬ãƒãƒ¼ãƒˆã§é™³è…åŒ–ã‚’é˜²æ­¢ |
| ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³ | ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹è§£æã‹ã‚‰Mermaidãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ ã‚’è‡ªå‹•ç”Ÿæˆ |
| ADR | AI ã§ãƒ‰ãƒ©ãƒ•ãƒˆã‚’ç”Ÿæˆã—ã€è¨­è¨ˆåˆ¤æ–­ã®è¨˜éŒ²ã‚’åŠ¹ç‡åŒ– |

---

## æ¬¡ã«èª­ã‚€ã¹ãã‚¬ã‚¤ãƒ‰

- [AIãƒ‡ãƒãƒƒã‚°](./03-ai-debugging.md) -- AI ã‚’æ´»ç”¨ã—ãŸãƒ‡ãƒãƒƒã‚°åŠ¹ç‡åŒ–
- [AIã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°](./01-ai-coding.md) -- AI ã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã®å®Ÿè·µ
- [é–‹ç™ºã®æœªæ¥](../03-team/02-future-of-development.md) -- AI æ™‚ä»£ã®é–‹ç™ºãƒ—ãƒ­ã‚»ã‚¹å±•æœ›

---

## å‚è€ƒæ–‡çŒ®

1. **Docs for Developers** -- Jared Bhatt & Zachary Sarah Corleissen (Apress, 2021) -- é–‹ç™ºè€…å‘ã‘ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŸ·ç­†ã‚¬ã‚¤ãƒ‰
2. **Conventional Commits** -- https://www.conventionalcommits.org/ -- ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¦ç´„
3. **TypeDoc** -- https://typedoc.org/ -- TypeScript ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆãƒ„ãƒ¼ãƒ«
4. **OpenAPI Specification** -- https://spec.openapis.org/oas/latest.html -- REST API ä»•æ§˜ã®æ¨™æº–
