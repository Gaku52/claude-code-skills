# ğŸ“Š Python ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ»è‡ªå‹•åŒ–ã‚¬ã‚¤ãƒ‰

> **ç›®çš„**: Python ã‚’ä½¿ã£ãŸåŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€è‡ªå‹•åŒ–ã€ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã€ãƒ‡ãƒ¼ã‚¿åˆ†æã®å®Ÿè·µçš„ãªæ‰‹æ³•ã‚’ç¿’å¾—ã™ã‚‹

## ğŸ“š ç›®æ¬¡

1. [ãƒ‡ãƒ¼ã‚¿å‡¦ç†åŸºç¤](#ãƒ‡ãƒ¼ã‚¿å‡¦ç†åŸºç¤)
2. [ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†](#ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†)
3. [ãƒ‡ãƒ¼ã‚¿åˆ†æ](#ãƒ‡ãƒ¼ã‚¿åˆ†æ)
4. [Web ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°](#web-ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°)
5. [è‡ªå‹•åŒ–](#è‡ªå‹•åŒ–)
6. [ä¸¦åˆ—å‡¦ç†](#ä¸¦åˆ—å‡¦ç†)

---

## ãƒ‡ãƒ¼ã‚¿å‡¦ç†åŸºç¤

### ãƒªã‚¹ãƒˆãƒ»è¾æ›¸æ“ä½œ

**ãƒªã‚¹ãƒˆå†…åŒ…è¡¨è¨˜**:
```python
# åŸºæœ¬
numbers = [1, 2, 3, 4, 5]
squared = [n ** 2 for n in numbers]
# [1, 4, 9, 16, 25]

# æ¡ä»¶ä»˜ã
evens = [n for n in numbers if n % 2 == 0]
# [2, 4]

# è¤‡é›‘ãªå¤‰æ›
users = [
    {"name": "Alice", "age": 25},
    {"name": "Bob", "age": 30},
]
names = [user["name"].upper() for user in users if user["age"] >= 25]
# ['ALICE', 'BOB']

# ãƒã‚¹ãƒˆã—ãŸãƒ«ãƒ¼ãƒ—
matrix = [[1, 2], [3, 4], [5, 6]]
flattened = [num for row in matrix for num in row]
# [1, 2, 3, 4, 5, 6]
```

**è¾æ›¸å†…åŒ…è¡¨è¨˜**:
```python
# åŸºæœ¬
numbers = [1, 2, 3, 4, 5]
squared_dict = {n: n ** 2 for n in numbers}
# {1: 1, 2: 4, 3: 9, 4: 16, 5: 25}

# ã‚­ãƒ¼ãƒ»å€¤ã®å¤‰æ›
user = {"name": "Alice", "age": 25, "city": "Tokyo"}
upper_keys = {k.upper(): v for k, v in user.items()}
# {'NAME': 'Alice', 'AGE': 25, 'CITY': 'Tokyo'}

# ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
filtered = {k: v for k, v in user.items() if isinstance(v, str)}
# {'name': 'Alice', 'city': 'Tokyo'}

# 2ã¤ã®ãƒªã‚¹ãƒˆã‹ã‚‰è¾æ›¸ä½œæˆ
keys = ["name", "age", "city"]
values = ["Alice", 25, "Tokyo"]
user_dict = {k: v for k, v in zip(keys, values)}
# {'name': 'Alice', 'age': 25, 'city': 'Tokyo'}
```

### ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹

```python
from dataclasses import dataclass, field
from typing import List


@dataclass
class User:
    name: str
    age: int
    email: str
    tags: list[str] = field(default_factory=list)

    def __post_init__(self):
        if self.age < 0:
            raise ValueError("Age must be positive")


# ä½¿ç”¨ä¾‹
user = User(name="Alice", age=25, email="alice@example.com")
print(user)
# User(name='Alice', age=25, email='alice@example.com', tags=[])

user.tags.append("admin")
print(user.tags)
# ['admin']


@dataclass(frozen=True)  # ã‚¤ãƒŸãƒ¥ãƒ¼ã‚¿ãƒ–ãƒ«
class Point:
    x: int
    y: int


point = Point(x=10, y=20)
# point.x = 30  # Error: frozen dataclass
```

### ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ãƒ»ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿

**ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿**:
```python
# åŸºæœ¬
def count_up(max_count: int):
    """ã‚«ã‚¦ãƒ³ãƒˆã‚¢ãƒƒãƒ—ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿"""
    count = 0
    while count < max_count:
        yield count
        count += 1


for num in count_up(5):
    print(num)  # 0, 1, 2, 3, 4


# ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿å¼
squared = (n ** 2 for n in range(1000000))  # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„
first_10 = list(squared)[:10]


# ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ï¼‰
def read_large_file(file_path: str):
    """å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã‚’1è¡Œãšã¤å‡¦ç†"""
    with open(file_path) as f:
        for line in f:
            yield line.strip()


for line in read_large_file("large_file.txt"):
    process_line(line)
```

**itertools**:
```python
from itertools import (
    chain,
    combinations,
    groupby,
    islice,
    product,
)

# chain: è¤‡æ•°ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã‚’é€£çµ
list1 = [1, 2, 3]
list2 = [4, 5, 6]
combined = list(chain(list1, list2))
# [1, 2, 3, 4, 5, 6]

# combinations: çµ„ã¿åˆã‚ã›
items = ['A', 'B', 'C']
combos = list(combinations(items, 2))
# [('A', 'B'), ('A', 'C'), ('B', 'C')]

# product: ç›´ç©
colors = ['red', 'green']
sizes = ['S', 'M', 'L']
products = list(product(colors, sizes))
# [('red', 'S'), ('red', 'M'), ('red', 'L'), ('green', 'S'), ('green', 'M'), ('green', 'L')]

# groupby: ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
data = [
    {"name": "Alice", "dept": "Sales"},
    {"name": "Bob", "dept": "Sales"},
    {"name": "Charlie", "dept": "Engineering"},
]
data.sort(key=lambda x: x["dept"])  # ã‚°ãƒ«ãƒ¼ãƒ—åŒ–å‰ã«ã‚½ãƒ¼ãƒˆå¿…é ˆ

for dept, group in groupby(data, key=lambda x: x["dept"]):
    print(f"{dept}: {[user['name'] for user in group]}")
# Sales: ['Alice', 'Bob']
# Engineering: ['Charlie']

# islice: ã‚¹ãƒ©ã‚¤ã‚¹
numbers = range(100)
first_10 = list(islice(numbers, 10))
# [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
```

---

## ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†

### CSV å‡¦ç†

```python
import csv
from pathlib import Path
from typing import Iterator


def read_csv(file_path: str) -> Iterator[dict[str, str]]:
    """CSV ã‚’è¾æ›¸ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã¨ã—ã¦èª­ã¿è¾¼ã¿"""
    with open(file_path, newline='', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            yield row


def write_csv(file_path: str, data: list[dict[str, str]], fieldnames: list[str]):
    """è¾æ›¸ã®ãƒªã‚¹ãƒˆã‚’ CSV ã«æ›¸ãè¾¼ã¿"""
    with open(file_path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(data)


# ä½¿ç”¨ä¾‹
users = [
    {"name": "Alice", "age": "25", "city": "Tokyo"},
    {"name": "Bob", "age": "30", "city": "Osaka"},
]
write_csv("users.csv", users, fieldnames=["name", "age", "city"])

for user in read_csv("users.csv"):
    print(user["name"], user["age"])
```

**pandas ã§ CSV å‡¦ç†**:
```python
import pandas as pd

# CSV èª­ã¿è¾¼ã¿
df = pd.read_csv("users.csv")

# ãƒ‡ãƒ¼ã‚¿ç¢ºèª
print(df.head())
print(df.info())
print(df.describe())

# ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
adults = df[df["age"] >= 20]

# æ–°ã—ã„ã‚«ãƒ©ãƒ è¿½åŠ 
df["age_group"] = df["age"].apply(lambda age: "adult" if age >= 20 else "minor")

# ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
grouped = df.groupby("city")["age"].mean()

# CSV æ›¸ãè¾¼ã¿
df.to_csv("output.csv", index=False, encoding='utf-8')
```

### JSON å‡¦ç†

```python
import json
from pathlib import Path
from typing import Any


def read_json(file_path: str) -> dict[str, Any]:
    """JSON ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    with open(file_path, encoding='utf-8') as f:
        return json.load(f)


def write_json(file_path: str, data: dict[str, Any], indent: int = 2):
    """JSON ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿"""
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=indent, ensure_ascii=False)


# ä½¿ç”¨ä¾‹
data = {
    "users": [
        {"name": "Alice", "age": 25},
        {"name": "Bob", "age": 30},
    ]
}
write_json("data.json", data)

loaded = read_json("data.json")
print(loaded["users"][0]["name"])  # Alice


# JSON Lines (JSONL) å‡¦ç†
def read_jsonl(file_path: str) -> Iterator[dict[str, Any]]:
    """JSONL ã‚’1è¡Œãšã¤èª­ã¿è¾¼ã¿"""
    with open(file_path, encoding='utf-8') as f:
        for line in f:
            yield json.loads(line.strip())


def write_jsonl(file_path: str, data: list[dict[str, Any]]):
    """JSONL ã«æ›¸ãè¾¼ã¿"""
    with open(file_path, 'w', encoding='utf-8') as f:
        for item in data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
```

### Excel å‡¦ç†

```bash
# ä¾å­˜é–¢ä¿‚è¿½åŠ 
pip install openpyxl pandas
```

```python
import pandas as pd


# Excel èª­ã¿è¾¼ã¿
df = pd.read_excel("data.xlsx", sheet_name="Sheet1")

# è¤‡æ•°ã‚·ãƒ¼ãƒˆèª­ã¿è¾¼ã¿
dfs = pd.read_excel("data.xlsx", sheet_name=None)  # ã™ã¹ã¦ã®ã‚·ãƒ¼ãƒˆ
for sheet_name, df in dfs.items():
    print(f"Sheet: {sheet_name}")
    print(df.head())

# Excel æ›¸ãè¾¼ã¿
df.to_excel("output.xlsx", index=False, sheet_name="Results")

# è¤‡æ•°ã‚·ãƒ¼ãƒˆæ›¸ãè¾¼ã¿
with pd.ExcelWriter("multi_sheet.xlsx") as writer:
    df1.to_excel(writer, sheet_name="Sheet1", index=False)
    df2.to_excel(writer, sheet_name="Sheet2", index=False)
```

**openpyxl ã§ç›´æ¥æ“ä½œ**:
```python
from openpyxl import Workbook, load_workbook


# æ–°è¦ä½œæˆ
wb = Workbook()
ws = wb.active
ws.title = "Users"

# ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿
ws['A1'] = "Name"
ws['B1'] = "Age"
ws.append(["Alice", 25])
ws.append(["Bob", 30])

wb.save("users.xlsx")


# æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
wb = load_workbook("users.xlsx")
ws = wb["Users"]

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
for row in ws.iter_rows(min_row=2, values_only=True):
    name, age = row
    print(f"{name}: {age}")

wb.close()
```

---

## ãƒ‡ãƒ¼ã‚¿åˆ†æ

### pandas åŸºç¤

```bash
pip install pandas numpy matplotlib
```

**åŸºæœ¬æ“ä½œ**:
```python
import pandas as pd
import numpy as np


# DataFrame ä½œæˆ
df = pd.DataFrame({
    "name": ["Alice", "Bob", "Charlie"],
    "age": [25, 30, 35],
    "city": ["Tokyo", "Osaka", "Tokyo"],
    "salary": [50000, 60000, 70000],
})

# ãƒ‡ãƒ¼ã‚¿ç¢ºèª
print(df.head())
print(df.info())
print(df.describe())

# ã‚«ãƒ©ãƒ é¸æŠ
names = df["name"]
subset = df[["name", "age"]]

# è¡Œé¸æŠ
first_row = df.iloc[0]
tokyo_users = df[df["city"] == "Tokyo"]
high_salary = df[df["salary"] >= 60000]

# è¤‡æ•°æ¡ä»¶
tokyo_adults = df[(df["city"] == "Tokyo") & (df["age"] >= 30)]

# ã‚½ãƒ¼ãƒˆ
sorted_df = df.sort_values("age", ascending=False)

# é›†è¨ˆ
print(df["age"].mean())
print(df["salary"].sum())
print(df.groupby("city")["salary"].mean())
```

**ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°**:
```python
# æ¬ æå€¤å‡¦ç†
df = pd.DataFrame({
    "name": ["Alice", "Bob", None],
    "age": [25, None, 35],
})

# æ¬ æå€¤ç¢ºèª
print(df.isnull().sum())

# æ¬ æå€¤å‰Šé™¤
df_dropped = df.dropna()

# æ¬ æå€¤è£œå®Œ
df_filled = df.fillna({"age": df["age"].mean()})

# é‡è¤‡å‰Šé™¤
df_unique = df.drop_duplicates()

# å‹å¤‰æ›
df["age"] = df["age"].astype(int)
```

**ãƒ‡ãƒ¼ã‚¿çµåˆ**:
```python
users = pd.DataFrame({
    "user_id": [1, 2, 3],
    "name": ["Alice", "Bob", "Charlie"],
})

orders = pd.DataFrame({
    "order_id": [101, 102, 103],
    "user_id": [1, 1, 2],
    "amount": [100, 200, 150],
})

# Inner Join
merged = pd.merge(users, orders, on="user_id", how="inner")

# Left Join
merged_left = pd.merge(users, orders, on="user_id", how="left")

# Concat (ç¸¦æ–¹å‘)
df1 = pd.DataFrame({"name": ["Alice"]})
df2 = pd.DataFrame({"name": ["Bob"]})
combined = pd.concat([df1, df2], ignore_index=True)
```

### ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–

```python
import matplotlib.pyplot as plt
import pandas as pd


# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
df = pd.DataFrame({
    "month": ["Jan", "Feb", "Mar", "Apr", "May"],
    "sales": [100, 120, 140, 130, 160],
    "costs": [80, 90, 100, 95, 110],
})

# æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•
plt.figure(figsize=(10, 6))
plt.plot(df["month"], df["sales"], marker='o', label='Sales')
plt.plot(df["month"], df["costs"], marker='s', label='Costs')
plt.xlabel("Month")
plt.ylabel("Amount")
plt.title("Sales and Costs")
plt.legend()
plt.grid(True)
plt.savefig("sales_chart.png")
plt.close()

# æ£’ã‚°ãƒ©ãƒ•
plt.figure(figsize=(8, 6))
df.plot(x="month", y=["sales", "costs"], kind="bar")
plt.savefig("bar_chart.png")
plt.close()

# æ•£å¸ƒå›³
plt.figure(figsize=(8, 6))
plt.scatter(df["sales"], df["costs"])
plt.xlabel("Sales")
plt.ylabel("Costs")
plt.title("Sales vs Costs")
plt.savefig("scatter.png")
plt.close()
```

---

## Web ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°

### requests + BeautifulSoup

```bash
pip install requests beautifulsoup4 lxml
```

```python
import requests
from bs4 import BeautifulSoup
from typing import List


def scrape_articles(url: str) -> List[dict[str, str]]:
    """è¨˜äº‹ä¸€è¦§ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"""
    response = requests.get(url, headers={
        "User-Agent": "Mozilla/5.0 (compatible; MyBot/1.0)"
    })
    response.raise_for_status()

    soup = BeautifulSoup(response.content, 'lxml')
    articles = []

    for article in soup.select(".article-item"):
        title = article.select_one(".title").get_text(strip=True)
        link = article.select_one("a")["href"]
        date = article.select_one(".date").get_text(strip=True)

        articles.append({
            "title": title,
            "link": link,
            "date": date,
        })

    return articles


# ä½¿ç”¨ä¾‹
articles = scrape_articles("https://example.com/articles")
for article in articles:
    print(f"{article['title']} - {article['date']}")
```

**ãƒ¬ãƒ¼ãƒˆåˆ¶é™**:
```python
import time
import requests
from typing import List


def scrape_multiple_pages(base_url: str, max_pages: int = 10) -> List[dict]:
    """è¤‡æ•°ãƒšãƒ¼ã‚¸ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚ã‚Šï¼‰"""
    all_articles = []

    for page in range(1, max_pages + 1):
        url = f"{base_url}?page={page}"
        print(f"Scraping page {page}...")

        articles = scrape_articles(url)
        all_articles.extend(articles)

        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼ˆ1ç§’å¾…æ©Ÿï¼‰
        time.sleep(1)

    return all_articles
```

### Selenium ã§å‹•çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„

```bash
pip install selenium webdriver-manager
```

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager


def scrape_dynamic_content(url: str) -> List[dict[str, str]]:
    """JavaScript ã§ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã•ã‚Œã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"""
    # Chrome ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    service = Service(ChromeDriverManager().install())
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")  # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")

    driver = webdriver.Chrome(service=service, options=options)

    try:
        driver.get(url)

        # è¦ç´ ãŒèª­ã¿è¾¼ã¾ã‚Œã‚‹ã¾ã§å¾…æ©Ÿ
        wait = WebDriverWait(driver, 10)
        wait.until(EC.presence_of_element_located((By.CLASS_NAME, "article-item")))

        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
        articles = []
        elements = driver.find_elements(By.CLASS_NAME, "article-item")

        for element in elements:
            title = element.find_element(By.CLASS_NAME, "title").text
            link = element.find_element(By.TAG_NAME, "a").get_attribute("href")

            articles.append({
                "title": title,
                "link": link,
            })

        return articles

    finally:
        driver.quit()
```

---

## è‡ªå‹•åŒ–

### ã‚¹ã‚¯ãƒªãƒ—ãƒˆè‡ªå‹•åŒ–

**ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°**:
```python
import argparse
from pathlib import Path


def main():
    parser = argparse.ArgumentParser(description="CSV ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ„ãƒ¼ãƒ«")
    parser.add_argument("input", type=str, help="å…¥åŠ› CSV ãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("output", type=str, help="å‡ºåŠ› CSV ãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--filter-age", type=int, help="å¹´é½¢ãƒ•ã‚£ãƒ«ã‚¿")
    parser.add_argument("--verbose", "-v", action="store_true", help="è©³ç´°ãƒ­ã‚°")

    args = parser.parse_args()

    if args.verbose:
        print(f"Input: {args.input}")
        print(f"Output: {args.output}")

    # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
    df = pd.read_csv(args.input)

    if args.filter_age:
        df = df[df["age"] >= args.filter_age]

    df.to_csv(args.output, index=False)

    if args.verbose:
        print(f"Processed {len(df)} rows")


if __name__ == "__main__":
    main()
```

**å®Ÿè¡Œ**:
```bash
python process_csv.py input.csv output.csv --filter-age 20 --verbose
```

### ã‚¿ã‚¹ã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©

**cron (Linux/Mac)**:
```bash
# crontab ç·¨é›†
crontab -e

# æ¯æ—¥ 9:00 ã«å®Ÿè¡Œ
0 9 * * * /usr/bin/python3 /path/to/script.py

# æ¯æ™‚å®Ÿè¡Œ
0 * * * * /usr/bin/python3 /path/to/script.py

# æ¯é€±æœˆæ›œ 10:00 ã«å®Ÿè¡Œ
0 10 * * 1 /usr/bin/python3 /path/to/script.py
```

**Windows ã‚¿ã‚¹ã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©**:
```bash
# PowerShell ã§ä½œæˆ
$action = New-ScheduledTaskAction -Execute "python" -Argument "C:\path\to\script.py"
$trigger = New-ScheduledTaskTrigger -Daily -At 9am
Register-ScheduledTask -Action $action -Trigger $trigger -TaskName "DataProcessing"
```

**schedule ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆPythonï¼‰**:
```bash
pip install schedule
```

```python
import schedule
import time


def job():
    print("Running scheduled job...")
    # ãƒ‡ãƒ¼ã‚¿å‡¦ç†


# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­å®š
schedule.every().day.at("09:00").do(job)
schedule.every().hour.do(job)
schedule.every().monday.at("10:00").do(job)

# å®Ÿè¡Œãƒ«ãƒ¼ãƒ—
while True:
    schedule.run_pending()
    time.sleep(60)
```

### ãƒ¡ãƒ¼ãƒ«é€ä¿¡

```bash
pip install python-dotenv
```

```python
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.application import MIMEApplication
from pathlib import Path
import os
from dotenv import load_dotenv

load_dotenv()


def send_email(
    to: str,
    subject: str,
    body: str,
    attachments: list[str] | None = None
):
    """ãƒ¡ãƒ¼ãƒ«é€ä¿¡"""
    # SMTP è¨­å®š
    smtp_host = os.getenv("SMTP_HOST", "smtp.gmail.com")
    smtp_port = int(os.getenv("SMTP_PORT", "587"))
    smtp_user = os.getenv("SMTP_USER")
    smtp_password = os.getenv("SMTP_PASSWORD")

    # ãƒ¡ãƒ¼ãƒ«ä½œæˆ
    msg = MIMEMultipart()
    msg["From"] = smtp_user
    msg["To"] = to
    msg["Subject"] = subject

    # æœ¬æ–‡
    msg.attach(MIMEText(body, "plain"))

    # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«
    if attachments:
        for file_path in attachments:
            with open(file_path, "rb") as f:
                part = MIMEApplication(f.read(), Name=Path(file_path).name)
                part["Content-Disposition"] = f'attachment; filename="{Path(file_path).name}"'
                msg.attach(part)

    # é€ä¿¡
    with smtplib.SMTP(smtp_host, smtp_port) as server:
        server.starttls()
        server.login(smtp_user, smtp_password)
        server.send_message(msg)


# ä½¿ç”¨ä¾‹
send_email(
    to="recipient@example.com",
    subject="Daily Report",
    body="Please find the daily report attached.",
    attachments=["report.csv", "chart.png"]
)
```

**.env**:
```bash
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your-email@gmail.com
SMTP_PASSWORD=your-app-password
```

---

## ä¸¦åˆ—å‡¦ç†

### multiprocessing

```python
from multiprocessing import Pool
from typing import List
import time


def process_item(item: int) -> int:
    """é‡ã„å‡¦ç†ï¼ˆä¾‹: è¨ˆç®—ï¼‰"""
    time.sleep(0.1)
    return item ** 2


def process_sequential(items: List[int]) -> List[int]:
    """é€æ¬¡å‡¦ç†"""
    return [process_item(item) for item in items]


def process_parallel(items: List[int], num_workers: int = 4) -> List[int]:
    """ä¸¦åˆ—å‡¦ç†"""
    with Pool(processes=num_workers) as pool:
        results = pool.map(process_item, items)
    return results


# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
items = list(range(100))

start = time.time()
results_seq = process_sequential(items)
print(f"Sequential: {time.time() - start:.2f}s")

start = time.time()
results_par = process_parallel(items, num_workers=4)
print(f"Parallel: {time.time() - start:.2f}s")
```

### concurrent.futures

```python
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
import requests
from typing import List


def fetch_url(url: str) -> dict[str, str]:
    """URL ã‚’å–å¾—ï¼ˆI/O ãƒã‚¦ãƒ³ãƒ‰ï¼‰"""
    response = requests.get(url)
    return {"url": url, "status": response.status_code}


def process_urls_parallel(urls: List[str], max_workers: int = 10) -> List[dict]:
    """è¤‡æ•° URL ã‚’ä¸¦åˆ—ã§å–å¾—"""
    results = []

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Future ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
        future_to_url = {executor.submit(fetch_url, url): url for url in urls}

        # å®Œäº†ã—ãŸã‚‚ã®ã‹ã‚‰å–å¾—
        for future in as_completed(future_to_url):
            url = future_to_url[future]
            try:
                result = future.result()
                results.append(result)
            except Exception as exc:
                print(f"{url} generated an exception: {exc}")

    return results


# CPU ãƒã‚¦ãƒ³ãƒ‰ãªå‡¦ç†ã¯ ProcessPoolExecutor
def cpu_bound_task(n: int) -> int:
    return sum(i * i for i in range(n))


def process_cpu_bound(numbers: List[int]) -> List[int]:
    with ProcessPoolExecutor(max_workers=4) as executor:
        results = list(executor.map(cpu_bound_task, numbers))
    return results
```

### asyncio ã§éåŒæœŸå‡¦ç†

```bash
pip install aiohttp aiofiles
```

```python
import asyncio
import aiohttp
from typing import List


async def fetch_url_async(session: aiohttp.ClientSession, url: str) -> dict[str, str]:
    """éåŒæœŸã§ URL ã‚’å–å¾—"""
    async with session.get(url) as response:
        return {"url": url, "status": response.status}


async def fetch_all_urls(urls: List[str]) -> List[dict]:
    """è¤‡æ•° URL ã‚’éåŒæœŸã§å–å¾—"""
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_url_async(session, url) for url in urls]
        results = await asyncio.gather(*tasks)
        return results


# å®Ÿè¡Œ
urls = [
    "https://example.com/page1",
    "https://example.com/page2",
    "https://example.com/page3",
]

results = asyncio.run(fetch_all_urls(urls))
for result in results:
    print(f"{result['url']}: {result['status']}")


# ãƒ•ã‚¡ã‚¤ãƒ«éåŒæœŸå‡¦ç†
import aiofiles


async def write_file_async(file_path: str, content: str):
    """éåŒæœŸã§ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿"""
    async with aiofiles.open(file_path, 'w') as f:
        await f.write(content)


async def read_file_async(file_path: str) -> str:
    """éåŒæœŸã§ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
    async with aiofiles.open(file_path, 'r') as f:
        return await f.read()


async def process_files():
    """è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’éåŒæœŸå‡¦ç†"""
    await asyncio.gather(
        write_file_async("file1.txt", "Content 1"),
        write_file_async("file2.txt", "Content 2"),
        write_file_async("file3.txt", "Content 3"),
    )


asyncio.run(process_files())
```

---

## ã¾ã¨ã‚

### ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

**åŸºæœ¬**:
- [ ] ãƒªã‚¹ãƒˆãƒ»è¾æ›¸å†…åŒ…è¡¨è¨˜ã§åŠ¹ç‡çš„ãªå‡¦ç†
- [ ] ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã§å‹å®‰å…¨æ€§ç¢ºä¿
- [ ] ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã§ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
- [ ] itertools ã§è¤‡é›‘ãªå‡¦ç†ã‚’ç°¡æ½”ã«

**ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†**:
- [ ] CSV: csv / pandas
- [ ] JSON: json / JSONL
- [ ] Excel: openpyxl / pandas

**ãƒ‡ãƒ¼ã‚¿åˆ†æ**:
- [ ] pandas ã§é›†è¨ˆãƒ»åˆ†æ
- [ ] æ¬ æå€¤ãƒ»é‡è¤‡å‰Šé™¤ã§ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°
- [ ] matplotlib ã§å¯è¦–åŒ–

**ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°**:
- [ ] requests + BeautifulSoup ã§åŸºæœ¬ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
- [ ] Selenium ã§å‹•çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
- [ ] ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã§è² è·è»½æ¸›

**è‡ªå‹•åŒ–**:
- [ ] argparse ã§ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°
- [ ] schedule / cron ã§å®šæœŸå®Ÿè¡Œ
- [ ] smtplib ã§ãƒ¡ãƒ¼ãƒ«é€ä¿¡

**ä¸¦åˆ—å‡¦ç†**:
- [ ] multiprocessing ã§ CPU ãƒã‚¦ãƒ³ãƒ‰å‡¦ç†
- [ ] ThreadPoolExecutor ã§ I/O ãƒã‚¦ãƒ³ãƒ‰å‡¦ç†
- [ ] asyncio ã§éåŒæœŸå‡¦ç†

---

## å®Ÿè·µä¾‹: ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```python
import pandas as pd
import requests
from pathlib import Path
from datetime import datetime
import smtplib
from email.mime.text import MIMEText


def fetch_data() -> pd.DataFrame:
    """API ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—"""
    response = requests.get("https://api.example.com/sales")
    data = response.json()
    return pd.DataFrame(data)


def process_data(df: pd.DataFrame) -> pd.DataFrame:
    """ãƒ‡ãƒ¼ã‚¿å‡¦ç†"""
    # æ¬ æå€¤å‰Šé™¤
    df = df.dropna()

    # é›†è¨ˆ
    df["total"] = df["quantity"] * df["price"]

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    df = df[df["total"] >= 1000]

    return df


def generate_report(df: pd.DataFrame, output_path: str):
    """ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    # çµ±è¨ˆæƒ…å ±
    summary = {
        "total_sales": df["total"].sum(),
        "avg_sales": df["total"].mean(),
        "num_orders": len(df),
    }

    # CSV å‡ºåŠ›
    df.to_csv(output_path, index=False)

    return summary


def send_report(summary: dict, file_path: str):
    """ãƒ¬ãƒãƒ¼ãƒˆé€ä¿¡"""
    body = f"""
    Daily Sales Report

    Total Sales: ${summary['total_sales']:,.2f}
    Average Sales: ${summary['avg_sales']:,.2f}
    Number of Orders: {summary['num_orders']}
    """

    send_email(
        to="manager@example.com",
        subject=f"Sales Report - {datetime.now().strftime('%Y-%m-%d')}",
        body=body,
        attachments=[file_path]
    )


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("Fetching data...")
    df = fetch_data()

    print("Processing data...")
    df = process_data(df)

    print("Generating report...")
    output_path = f"sales_report_{datetime.now().strftime('%Y%m%d')}.csv"
    summary = generate_report(df, output_path)

    print("Sending report...")
    send_report(summary, output_path)

    print("Done!")


if __name__ == "__main__":
    main()
```

**cron ã§æ¯æ—¥å®Ÿè¡Œ**:
```bash
# æ¯æ—¥ 9:00 ã«å®Ÿè¡Œ
0 9 * * * /usr/bin/python3 /path/to/sales_report.py
```

---

*åŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿å‡¦ç†ã§æ¥­å‹™ã‚’è‡ªå‹•åŒ–ã—ã¾ã—ã‚‡ã†ã€‚*
