# CPUアーキテクチャ

> CPUは「フェッチ→デコード→実行→ライトバック」を1秒間に数十億回繰り返す、計算の心臓部である。

## この章で学ぶこと

- [ ] CPUの命令サイクルを4段階で説明できる
- [ ] パイプライン処理とその限界（ハザード）を理解する
- [ ] CISC vs RISCの設計哲学の違いを説明できる

## 前提知識

- 2進数の基礎 → 参照: [[../02-data-representation/00-binary-and-number-systems.md]]

---

## 1. CPUの基本構造

### 1.1 CPU の主要コンポーネント

```
┌─────────────────────────────────────────────────────────────┐
│                        CPU                                  │
│  ┌──────────────────────────────────────────────────────┐   │
│  │                   制御ユニット (CU)                   │   │
│  │  ┌──────────┐  ┌──────────┐  ┌──────────────────┐   │   │
│  │  │ 命令      │  │ プログラム│  │ 命令デコーダ     │   │   │
│  │  │ レジスタ  │  │ カウンタ  │  │                  │   │   │
│  │  │ (IR)      │  │ (PC)      │  │                  │   │   │
│  │  └──────────┘  └──────────┘  └──────────────────┘   │   │
│  └──────────────────────────────────────────────────────┘   │
│                                                             │
│  ┌──────────────────┐  ┌────────────────────────────────┐  │
│  │  ALU             │  │  レジスタファイル              │  │
│  │  (算術論理演算   │  │  ┌────┐ ┌────┐ ┌────┐ ┌────┐ │  │
│  │   ユニット)      │  │  │ R0 │ │ R1 │ │ R2 │ │ R3 │ │  │
│  │                  │  │  └────┘ └────┘ └────┘ └────┘ │  │
│  │  ┌──────────┐   │  │  ┌────┐ ┌────┐ ┌────┐ ┌────┐ │  │
│  │  │ 加算器   │   │  │  │ R4 │ │ R5 │ │ R6 │ │ R7 │ │  │
│  │  │ 乗算器   │   │  │  └────┘ └────┘ └────┘ └────┘ │  │
│  │  │ 比較器   │   │  │  ... (x86: 16個, ARM: 31個)   │  │
│  │  │ シフタ   │   │  │                                │  │
│  │  └──────────┘   │  │  ┌──────────────────────────┐ │  │
│  └──────────────────┘  │  │ フラグレジスタ (EFLAGS)  │ │  │
│                         │  │ Zero, Carry, Overflow... │ │  │
│                         │  └──────────────────────────┘ │  │
│  ┌──────────────────┐  └────────────────────────────────┘  │
│  │  キャッシュ      │                                      │
│  │  L1i: 64KB       │  ← 命令キャッシュ                   │
│  │  L1d: 64KB       │  ← データキャッシュ                  │
│  └──────────────────┘                                      │
│                                                             │
└──────────────────────────┬──────────────────────────────────┘
                           │ バス（メモリバス）
                           ▼
                    ┌────────────┐
                    │  メインメモリ │
                    │  (RAM)      │
                    └────────────┘
```

### 1.2 各コンポーネントの役割

| コンポーネント | 役割 | 類似物 |
|-------------|------|--------|
| **ALU** | 算術演算（加減乗除）と論理演算（AND/OR/NOT）を実行 | 計算機 |
| **制御ユニット** | 命令のデコードと実行制御、他コンポーネントへの信号送出 | 指揮者 |
| **レジスタ** | CPU内部の超高速記憶装置（1クロックでアクセス可能） | メモ帳 |
| **PC（プログラムカウンタ）** | 次に実行する命令のアドレスを保持 | 本の栞 |
| **IR（命令レジスタ）** | 現在実行中の命令を保持 | 今読んでいる行 |
| **キャッシュ** | メインメモリのコピーを保持し高速アクセスを提供 | 手元の参考書 |

---

## 2. 命令サイクル

### 2.1 基本4段階

CPUは全ての命令を以下の4段階で処理する:

```
命令サイクル（4段階）:

  ┌─────────┐    ┌─────────┐    ┌─────────┐    ┌─────────────┐
  │  Fetch   │───→│  Decode  │───→│ Execute  │───→│ Write Back  │
  │  取得    │    │  解読    │    │  実行    │    │  書き戻し   │
  └─────────┘    └─────────┘    └─────────┘    └─────────────┘
       │               │              │               │
  PC のアドレス    命令を解析     ALUで演算      結果をレジスタ
  からメモリの    してオペコード  またはメモリ    またはメモリに
  命令を読む      とオペランド   アクセスを実行   格納する
                   を特定

  例: ADD R1, R2, R3 (R1 = R2 + R3)
  1. Fetch:   PC=0x1000 のメモリから命令 "ADD R1,R2,R3" を取得
  2. Decode:  「ADD」= 加算、ソース: R2とR3、デスト: R1 と解析
  3. Execute: ALUで R2の値 + R3の値 を計算
  4. Write:   結果を R1 に格納、PC を次の命令へ進める
```

### 2.2 具体例: アセンブリ命令の実行

```nasm
; x86-64 アセンブリ: 2つの数値を加算
; C言語の a = b + c に相当

mov rax, [rbp-8]    ; Fetch→Decode→Execute: メモリからbの値をraxにロード
add rax, [rbp-16]   ; Fetch→Decode→Execute: raxにcの値を加算
mov [rbp-24], rax   ; Fetch→Decode→Execute: 結果をメモリ(a)にストア

; 各命令が4段階を経る。
; 1命令 = 1クロックサイクルではない（複数サイクルかかる場合が多い）。
; パイプラインで高速化される（後述）。
```

---

## 3. パイプライン処理

### 3.1 基本概念

パイプライン処理は、複数の命令の各段階を重ね合わせることで、スループットを向上させる。

```
パイプラインなし（逐次実行）:
  時間 →  1  2  3  4  5  6  7  8  9  10 11 12
  命令1:  F  D  E  W
  命令2:              F  D  E  W
  命令3:                          F  D  E  W
  → 3命令に12クロック

5段パイプライン:
  時間 →  1  2  3  4  5  6  7
  命令1:  F  D  E  M  W
  命令2:     F  D  E  M  W
  命令3:        F  D  E  M  W
  → 3命令に7クロック（理想時は5+n-1クロック）

  F=Fetch  D=Decode  E=Execute  M=Memory  W=WriteBack
```

5段パイプラインでは、理想的にはクロックサイクルごとに1命令が完了する。ただし、**パイプラインハザード**があるとこの理想は崩れる。

### 3.2 パイプラインハザード（3種類）

```
┌───────────────────────────────────────────────────────┐
│              パイプラインハザード 3種                   │
├───────────────────────────────────────────────────────┤
│                                                       │
│  1. データハザード（Data Hazard）                      │
│     前の命令の結果を次の命令が使う                     │
│     ADD R1, R2, R3   ; R1 = R2 + R3                  │
│     SUB R4, R1, R5   ; R4 = R1 - R5 ← R1がまだ未完成│
│     対策: フォワーディング（バイパス）                 │
│                                                       │
│  2. 制御ハザード（Control Hazard）                    │
│     分岐命令で次の命令のアドレスが不明                 │
│     BEQ R1, R2, label ; R1==R2なら分岐               │
│     ??? ; labelに飛ぶかどうか、実行するまで不明       │
│     対策: 分岐予測（Branch Prediction）               │
│                                                       │
│  3. 構造ハザード（Structural Hazard）                 │
│     同じハードウェア資源を同時に使おうとする           │
│     命令FetchとデータMemoryが同じメモリポートを使う    │
│     対策: 資源の複製（L1i と L1d の分離等）           │
│                                                       │
└───────────────────────────────────────────────────────┘
```

### 3.3 分岐予測（Branch Prediction）

現代のCPUは**分岐予測器**を搭載し、条件分岐の結果を予測して投機的に実行する。

```
分岐予測の精度（現代CPU）:

  静的予測（常に「分岐しない」と予測）:  〜60%
  1ビットカウンタ:                        〜85%
  2ビットカウンタ:                        〜90%
  相関予測器:                             〜95%
  TAGE（現代CPU）:                        〜97%

  予測ミスのペナルティ: 10〜20クロックサイクル
  → ミス率3%でも、頻繁な分岐ではパフォーマンスに大きく影響
```

**プログラマーへの影響**: 分岐予測ミスを減らすことでパフォーマンスが向上する。

```c
// 分岐予測の影響を測定する例（C言語）

#include <stdio.h>
#include <stdlib.h>
#include <time.h>

#define SIZE 32768

int main() {
    int data[SIZE];
    for (int i = 0; i < SIZE; i++)
        data[i] = rand() % 256;

    // テスト1: ソート済み配列（分岐予測が効く）
    // qsort(data, SIZE, sizeof(int), compare); // ソートする場合

    clock_t start = clock();
    long sum = 0;
    for (int i = 0; i < 100000; i++) {
        for (int j = 0; j < SIZE; j++) {
            if (data[j] >= 128)  // この分岐が予測される
                sum += data[j];
        }
    }
    clock_t end = clock();

    printf("Sum: %ld, Time: %f sec\n", sum,
           (double)(end - start) / CLOCKS_PER_SEC);

    // ソート済みの場合:  〜6秒（分岐予測ほぼ100%ヒット）
    // 未ソートの場合:  〜18秒（分岐予測ミス多発）
    // → 同じ計算で3倍の差！

    return 0;
}
```

---

## 4. CISC vs RISC

### 4.1 設計哲学の違い

```
CISC (Complex Instruction Set Computer):
  「1命令で多くの仕事をさせる」
  → x86/x64 (Intel, AMD)

  特徴:
  - 命令が可変長（1〜15バイト）
  - 1命令でメモリアクセス+演算が可能
  - マイクロコードで内部的にRISC命令に変換
  - 命令数が多い（1000+）

RISC (Reduced Instruction Set Computer):
  「命令を単純にし、パイプラインを効率化する」
  → ARM, RISC-V, MIPS

  特徴:
  - 命令が固定長（4バイト）
  - Load/Store アーキテクチャ（メモリアクセスは専用命令のみ）
  - パイプラインに最適化
  - 命令数が少ない（〜200）
```

### 4.2 比較表

| 項目 | CISC (x86) | RISC (ARM) |
|------|-----------|------------|
| **代表** | Intel Core, AMD Ryzen | Apple M4, Snapdragon, RISC-V |
| **命令長** | 可変長 (1-15バイト) | 固定長 (4バイト) |
| **命令数** | 1000+ | 〜200 |
| **メモリアクセス** | 演算命令で直接可能 | Load/Store命令のみ |
| **レジスタ数** | 16個 (x64) | 31個 (AArch64) |
| **消費電力** | 高い (15-125W) | 低い (1-15W) |
| **得意分野** | デスクトップ、サーバー | モバイル、組み込み、最近はサーバーも |
| **互換性** | 40年以上の後方互換性 | バージョン間で変更あり |

### 4.3 同じ処理のアセンブリ比較

```nasm
; 処理: memory[C] = memory[A] + memory[B]

; === x86 (CISC) ===
mov eax, [A]       ; メモリからレジスタにロード + 演算が1命令で可能
add eax, [B]       ; メモリから直接加算
mov [C], eax       ; 結果をメモリに格納
; 3命令

; === ARM (RISC) ===
ldr r0, [r3]       ; メモリからレジスタにロード（Load）
ldr r1, [r4]       ; メモリからレジスタにロード（Load）
add r2, r0, r1     ; レジスタ同士の加算（演算）
str r2, [r5]       ; レジスタからメモリにストア（Store）
; 4命令（Load/Storeが分離されている）

; CISCの方が命令数は少ないが、
; RISCの各命令は1クロックで実行でき、パイプラインが効率的。
```

---

## 5. マルチコアとハイパースレッディング

### 5.1 マルチコア

```
シングルコア vs マルチコア:

  シングルコア（2005年以前）:
  ┌──────────┐
  │  Core 0  │ ← 1つのコアで全処理
  └──────────┘
  → クロック周波数を上げるしかない
  → 発熱限界（Power Wall）に到達

  マルチコア（現代）:
  ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐
  │  Core 0  │ │  Core 1  │ │  Core 2  │ │  Core 3  │
  └──────────┘ └──────────┘ └──────────┘ └──────────┘
        │            │            │            │
        └────────────┴────────────┴────────────┘
                          │
                    共有 L3 キャッシュ
  → 並列に処理を実行できる
  → ただし並列化できないタスクには効果なし（アムダールの法則）
```

### 5.2 ハイパースレッディング（SMT）

1つの物理コアに2つの論理スレッドを載せる技術。

```
ハイパースレッディング:

  物理コア1個:
  ┌────────────────────────────────┐
  │  ┌─────────┐  ┌─────────┐    │
  │  │ Thread 0 │  │ Thread 1 │    │
  │  │ (論理CPU0)│  │ (論理CPU1)│   │
  │  └─────────┘  └─────────┘    │
  │         │            │        │
  │         └──┬─────────┘        │
  │            ▼                  │
  │     ┌──────────┐              │
  │     │  共有ALU  │              │
  │     │  共有Cache│              │
  │     └──────────┘              │
  └────────────────────────────────┘

  効果: 15-30%のスループット向上（2倍にはならない）
  理由: ALUやキャッシュは共有なので、同時実行は限定的
```

---

## 6. Apple Silicon の革新

### 6.1 Apple M1〜M4 の設計思想

```
従来のPC:
  CPU(Intel) + GPU(NVIDIA) + RAM(別チップ)
  → それぞれが別チップ、バスで接続
  → データ移動のオーバーヘッドが大きい

Apple Silicon (SoC: System on Chip):
  ┌──────────────────────────────────────┐
  │            Apple M4 Max              │
  │  ┌──────────┐  ┌──────────────────┐ │
  │  │ P-Cores  │  │ E-Cores          │ │
  │  │ (性能)×12│  │ (効率)×4          │ │
  │  └──────────┘  └──────────────────┘ │
  │  ┌──────────┐  ┌──────────────────┐ │
  │  │ GPU      │  │ Neural Engine    │ │
  │  │ 40コア   │  │ 16コア           │ │
  │  └──────────┘  └──────────────────┘ │
  │  ┌──────────────────────────────────┐│
  │  │     統合メモリ (128GB LPDDR5)    ││
  │  │     CPU/GPU/NPU全てが直接アクセス ││
  │  └──────────────────────────────────┘│
  └──────────────────────────────────────┘
  → 全コンポーネントが同じチップ上
  → 統合メモリでデータコピー不要
  → 電力効率が劇的に向上（同性能で消費電力1/3〜1/5）
```

### 6.2 big.LITTLE（効率コア+性能コア）

| 種類 | 目的 | クロック | 消費電力 | 使用場面 |
|------|------|---------|---------|---------|
| P-Core (Performance) | 最大性能 | 高 (〜4.5GHz) | 高 | コンパイル、レンダリング |
| E-Core (Efficiency) | 省電力 | 低 (〜2.8GHz) | 低 | メール、ブラウジング |

→ OSのスケジューラが負荷に応じて自動的に使い分ける。

---

## 7. 命令レベル並列性（ILP）

### 7.1 スーパースカラ実行

1クロックサイクルで複数の命令を同時実行する。

```
スカラ（1命令/サイクル）:
  Clock:  1    2    3    4    5
  Inst:  ADD  MUL  SUB  AND  OR

スーパースカラ（2命令/サイクル）:
  Clock:  1       2       3
  Inst:  ADD     SUB     OR
         MUL     AND
  → 同じ5命令が3クロックで完了
```

### 7.2 アウトオブオーダー実行

命令をプログラムの順序通りではなく、**依存関係がない命令を先に実行**する。

```python
# 元のコード:
a = load(addr1)   # メモリアクセス: 100サイクル待ち
b = a + 1         # aに依存 → 待機
c = load(addr2)   # aに無関係 → 先に実行可能!
d = c * 2         # cに依存

# アウトオブオーダー実行:
# サイクル1: load(addr1) 開始、load(addr2) も同時に開始
# サイクル100: 両方のloadが完了
# サイクル101: a+1 と c*2 を並列実行
# → 順序通りなら200+サイクル → 実際は〜102サイクル
```

---

## 8. キャッシュフレンドリーなプログラミング

```c
// キャッシュの効果を実感する例

#include <stdio.h>
#include <time.h>

#define N 10000

int matrix[N][N];

// ❌ キャッシュ非効率: 列優先アクセス
void sum_column_major() {
    long sum = 0;
    for (int col = 0; col < N; col++)       // 外側が列
        for (int row = 0; row < N; row++)   // 内側が行
            sum += matrix[row][col];         // メモリ上で飛び飛び
    // 各アクセスが別のキャッシュラインを参照 → キャッシュミス多発
}

// ✅ キャッシュ効率的: 行優先アクセス
void sum_row_major() {
    long sum = 0;
    for (int row = 0; row < N; row++)       // 外側が行
        for (int col = 0; col < N; col++)   // 内側が列
            sum += matrix[row][col];         // メモリ上で連続
    // 1つのキャッシュラインで複数要素をカバー → ヒット率高い
}

// 性能差: 行優先は列優先の3〜10倍高速（N=10000の場合）
// 理由: L1キャッシュのライン（64バイト）に連続データが乗るため
```

```
メモリレイアウトの図解:

  C言語の2次元配列 int matrix[3][4] のメモリ配置:

  アドレス: 0x100  0x104  0x108  0x10C  0x110  0x114  ...
  値:       [0][0] [0][1] [0][2] [0][3] [1][0] [1][1] ...
            ←───── 行0 ─────→  ←───── 行1 ─────→

  行優先アクセス: [0][0]→[0][1]→[0][2]→[0][3]→[1][0]→...
  → メモリ上で連続 → キャッシュライン内でヒット ✅

  列優先アクセス: [0][0]→[1][0]→[2][0]→[0][1]→[1][1]→...
  → メモリ上で飛び飛び → 毎回キャッシュミス ❌
```

---

## 9. 実践演習

### 演習1: 命令サイクルのトレース（基礎）

以下の疑似アセンブリコードについて、各命令のFetch/Decode/Execute/WriteBackの各段階で何が起きるか記述せよ:

```
LOAD R1, 100    ; メモリ[100]の値をR1にロード
LOAD R2, 104    ; メモリ[104]の値をR2にロード
ADD  R3, R1, R2 ; R3 = R1 + R2
STORE R3, 108   ; R3の値をメモリ[108]にストア
```

### 演習2: パイプラインハザードの特定（応用）

以下の命令列でデータハザードが発生する箇所を特定し、フォワーディングで解決できるか検討せよ:

```
ADD  R1, R2, R3   ; R1 = R2 + R3
SUB  R4, R1, R5   ; R4 = R1 - R5  ← R1に依存
AND  R6, R1, R7   ; R6 = R1 & R7  ← R1に依存
OR   R8, R4, R9   ; R8 = R4 | R9  ← R4に依存
```

### 演習3: キャッシュ効率の実験（発展）

任意のプログラミング言語で、N×Nの行列の全要素の合計を計算するプログラムを2つ書け:
1. 行優先アクセス版
2. 列優先アクセス版

N=5000, 10000, 20000 で実行時間を比較し、結果をグラフ化せよ。

---

## FAQ

### Q1: クロック周波数が高い = 速いCPU ですか？

**A**: **必ずしもそうではない**。クロック周波数は「1秒間のサイクル数」であり、重要な指標の一つだが、以下も影響する:
- **IPC（Instructions Per Clock）**: 1サイクルで実行できる命令数
- **パイプラインの効率**: 分岐予測精度、ハザード処理
- **キャッシュ性能**: ヒット率、レイテンシ
- **メモリ帯域**: データの供給速度

Apple M4（3.5GHz）が Intel i9（5.8GHz）より速い場面があるのは、IPCが大幅に高いため。

### Q2: x86はなぜまだ使われているのですか？

**A**: **後方互換性**が最大の理由。40年以上のソフトウェア資産がx86バイナリで存在し、それらを動かし続ける必要がある。ただし:
- サーバー: AWS Graviton（ARM）への移行が進行中
- デスクトップ: Apple Siliconへの移行完了（Mac）
- モバイル: 最初からARM

x86は内部的にRISC風のマイクロオペレーションに変換して実行しているため、実質的にはRISCの利点も取り込んでいる。

### Q3: RISC-V は何が画期的ですか？

**A**: RISC-Vは**オープンソースの命令セットアーキテクチャ（ISA）**:
- ライセンス料不要（ARM は要ライセンス料）
- 誰でもRISC-V CPUを設計可能
- カスタム拡張が可能（AI用命令の追加など）
- 学術研究、IoT、組み込みで急速に普及中
- 中国が半導体自給のためRISC-Vに注力

---

## まとめ

| 概念 | ポイント |
|------|---------|
| 命令サイクル | Fetch→Decode→Execute→WriteBackの4段階 |
| パイプライン | 命令の各段階を重ね合わせてスループット向上 |
| ハザード | データ/制御/構造の3種、フォワーディングと分岐予測で対処 |
| CISC vs RISC | x86(複雑・互換性) vs ARM(単純・省電力) |
| マルチコア | 並列処理だが、アムダールの法則による限界あり |
| キャッシュ | メモリアクセスパターンがパフォーマンスを決定する |

---

## 次に読むべきガイド

→ [[01-memory-hierarchy.md]] — メモリ階層と局所性の原理

---

## 参考文献

1. Patterson, D. A. & Hennessy, J. L. "Computer Organization and Design: The Hardware/Software Interface." 6th Edition, Morgan Kaufmann, 2020.
2. Bryant, R. E. & O'Hallaron, D. R. "Computer Systems: A Programmer's Perspective." 3rd Edition, Pearson, 2015.
3. Hennessy, J. L. & Patterson, D. A. "Computer Architecture: A Quantitative Approach." 6th Edition, Morgan Kaufmann, 2017.
4. Intel 64 and IA-32 Architectures Software Developer Manuals. https://www.intel.com/
5. ARM Architecture Reference Manual. https://developer.arm.com/
6. Agner Fog. "The microarchitecture of Intel, AMD and VIA CPUs." https://agner.org/optimize/
