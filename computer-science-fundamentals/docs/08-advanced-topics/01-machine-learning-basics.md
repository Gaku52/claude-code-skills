# 機械学習入門

> 「機械学習とは、明示的にプログラムすることなく、コンピュータに学習する能力を与える研究分野である」——Arthur Samuel (1959)

## この章で学ぶこと

- [ ] 機械学習の3つのカテゴリを区別できる
- [ ] 主要なアルゴリズムの直感的理解を得る
- [ ] ニューラルネットワークと深層学習の基礎を知る

---

## 1. 機械学習とは何か

```
従来のプログラミング vs 機械学習:

  従来のプログラミング:
  ┌──────┐   ┌──────────┐   ┌──────┐
  │ルール │ + │データ    │ → │結果  │
  │(人が書く)│ │          │   │      │
  └──────┘   └──────────┘   └──────┘

  機械学習:
  ┌──────┐   ┌──────────┐   ┌──────┐
  │データ │ + │結果      │ → │ルール│
  │      │   │(正解ラベル)│   │(学習)│
  └──────┘   └──────────┘   └──────┘

  例: スパムフィルター
  従来: if "当選" in email → spam (ルールを手動作成)
  ML:   大量のスパム/非スパムメールから特徴を学習

機械学習が有効な場面:
  1. ルールが複雑すぎて手動で書けない（画像認識）
  2. ルールが常に変化する（スパム検出）
  3. 大量のデータからパターンを発見したい（レコメンド）
  4. 人間の直感が及ばない（タンパク質構造予測）
```

---

## 2. 機械学習の3つのカテゴリ

```
┌───────────────────────────────────────────────┐
│               機械学習                          │
├───────────────┬───────────────┬───────────────┤
│ 教師あり学習   │ 教師なし学習   │ 強化学習       │
│ Supervised    │ Unsupervised  │ Reinforcement │
├───────────────┼───────────────┼───────────────┤
│入力+正解ラベル │入力のみ       │状態+報酬      │
│               │               │               │
│分類:          │クラスタリング: │方策学習:      │
│ スパム判定    │ 顧客セグメント│ ゲームAI      │
│ 画像分類      │ 異常検知      │ ロボット制御   │
│               │               │               │
│回帰:          │次元削減:      │探索と活用:    │
│ 株価予測      │ PCA           │ AlphaGo       │
│ 気温予測      │ t-SNE         │ 自動運転       │
└───────────────┴───────────────┴───────────────┘
```

### 教師あり学習（Supervised Learning）

```
入力(X)と正解(y)のペアから関数 f: X → y を学習

  分類（Classification）:
  離散的なカテゴリを予測
  - メール → スパム / 非スパム
  - 画像 → 猫 / 犬 / 鳥
  - 腫瘍 → 良性 / 悪性

  回帰（Regression）:
  連続値を予測
  - 面積 → 家の価格
  - 気象データ → 明日の気温
  - 特徴量 → 売上予測

  学習プロセス:
  1. 訓練データ {(x₁,y₁), (x₂,y₂), ...} を用意
  2. モデルに入力して予測値 ŷ を計算
  3. 損失 L(y, ŷ) を計算（予測と正解の差）
  4. 損失を減らすようにパラメータを更新
  5. 2-4を繰り返す（エポック）
```

### 教師なし学習（Unsupervised Learning）

```
正解ラベルなしで、データの構造やパターンを発見

  クラスタリング:
  類似するデータをグループ化

  K-Means:
  1. K個の中心点をランダムに配置
  2. 各データを最も近い中心点のクラスタに割当
  3. 各クラスタの中心点を再計算
  4. 収束するまで2-3を繰り返す

       ●●●         ○○
      ●●●●        ○○○○
       ●●         ○○○
                ○

  次元削減:
  高次元データを低次元に圧縮
  - PCA: 分散最大の方向に射影
  - t-SNE: 高次元の近傍関係を保持して2D/3Dに可視化
  - UMAP: t-SNEより高速、グローバル構造を保持

  異常検知:
  正常パターンから外れたデータを検出
  → 不正取引検出、製造品質管理、システム監視
```

### 強化学習（Reinforcement Learning）

```
エージェントが環境と対話して報酬を最大化する行動方策を学習

  ┌────────┐   行動(a)   ┌────────┐
  │Agent   │───────────→│Environment│
  │(方策π) │←───────────│(状態遷移)│
  └────────┘  状態(s)    └────────┘
              報酬(r)

  例: 囲碁AI（AlphaGo）
  - 状態: 盤面の配置
  - 行動: 石を置く位置
  - 報酬: 勝ち(+1) / 負け(-1)
  - 方策: 盤面から最適な手を選ぶニューラルネットワーク

  探索と活用のジレンマ:
  - 探索(Exploration): 新しい行動を試す → 長期的に良い方策発見
  - 活用(Exploitation): 既知の最善手を取る → 短期的な報酬最大化
  → ε-greedy: 確率εで探索、1-εで活用
```

---

## 3. 主要なアルゴリズム

### 線形回帰

```
最もシンプルな回帰アルゴリズム

  モデル: y = wx + b
  (w: 重み, b: バイアス)

  目標: 予測値と正解の差（損失）を最小化
  損失関数: MSE = (1/n) Σ(yᵢ - ŷᵢ)²

  勾配降下法で最適化:
  w ← w - α × ∂L/∂w   (α: 学習率)
  b ← b - α × ∂L/∂b

  y │     ●
    │   ●    ────── 回帰直線
    │ ●  ●/
    │  /●
    │/●
    └──────── x

  多変量線形回帰: y = w₁x₁ + w₂x₂ + ... + wₙxₙ + b
  → 行列表記: y = Xw + b
```

### 決定木

```
条件分岐の繰り返しで予測

  例: ローン審査
          ┌──────────┐
          │年収>500万?│
          └──┬───┬───┘
         Yes │   │ No
       ┌─────┘   └─────┐
  ┌────┴────┐     ┌────┴────┐
  │勤続>3年? │     │  却下    │
  └──┬──┬───┘     └─────────┘
  Yes│  │No
  ┌──┘  └──┐
  │承認│  │審査│
  └────┘  └────┘

  分割基準:
  - ジニ不純度: クラスの混合度（0=純粋, 0.5=最大混合）
  - 情報利得: エントロピーの減少量
  - 分散削減: 回帰問題での分割基準

  利点: 解釈しやすい、前処理不要
  欠点: 過学習しやすい → アンサンブル手法で改善
```

### アンサンブル学習

```
複数の弱い学習器を組み合わせて強い学習器を作る

  1. ランダムフォレスト:
     複数の決定木を独立に学習 → 多数決/平均

     木1 → 猫     ╲
     木2 → 犬      ╲
     木3 → 猫  ───→ 多数決 → 猫
     木4 → 猫      ╱
     木5 → 犬     ╱

     各木はデータの一部（ブートストラップ）+
     特徴量の一部で学習 → 多様性を確保

  2. 勾配ブースティング:
     弱い学習器を逐次的に追加し、前の誤差を修正

     f(x) = f₁(x) + f₂(x) + f₃(x) + ...

     f₁: 初期モデル
     f₂: f₁の残差を学習
     f₃: f₁+f₂の残差を学習
     → 残差が減少していく

     実装: XGBoost, LightGBM, CatBoost
     → Kaggle競技の定番（テーブルデータ最強）

  比較:
  ┌──────────────┬──────────────┬──────────────┐
  │ 手法         │ 並列学習     │ 精度         │
  ├──────────────┼──────────────┼──────────────┤
  │ ランダムフォレスト│ ○（独立）  │ 良い         │
  │ 勾配ブースティング│ △（逐次的）│ 非常に良い   │
  └──────────────┴──────────────┴──────────────┘
```

---

## 4. ニューラルネットワーク

```
生物の神経細胞を模倣した計算モデル

  単一ニューロン（パーセプトロン）:
  入力: x₁, x₂, ..., xₙ
  重み: w₁, w₂, ..., wₙ
  出力: y = σ(w₁x₁ + w₂x₂ + ... + wₙxₙ + b)

  σ: 活性化関数
  ┌──────────────────────────────────────┐
  │ Sigmoid:  σ(z) = 1/(1+e⁻ᶻ)         │
  │ → 出力を0〜1に圧縮。確率として解釈   │
  │                                      │
  │ ReLU:     σ(z) = max(0, z)          │
  │ → 現代の標準。勾配消失問題を軽減     │
  │                                      │
  │ Softmax:  各クラスの確率を出力        │
  │ → 多クラス分類の出力層で使用          │
  └──────────────────────────────────────┘

  多層ニューラルネットワーク:
  ┌─────┐   ┌──────┐   ┌──────┐   ┌──────┐
  │入力層│──→│隠れ層1│──→│隠れ層2│──→│出力層│
  │(特徴)│   │      │   │      │   │(予測)│
  └─────┘   └──────┘   └──────┘   └──────┘

  ○─┐
  ○─┤──○─┐
  ○─┤  ○─┤──○─┐
  ○─┘  ○─┘  ○─┤──○  出力
       隠れ1  ○─┘
              隠れ2

  逆伝播法（Backpropagation）:
  1. 順伝播: 入力→出力を計算
  2. 損失計算: 予測と正解の差
  3. 逆伝播: 出力→入力方向に勾配を計算（連鎖律）
  4. パラメータ更新: 勾配降下法
  → これを大量データで繰り返す
```

---

## 5. 深層学習（Deep Learning）

```
「深い」ニューラルネットワーク（多くの隠れ層）

  なぜ2012年に爆発的に進化したか:
  1. 大量のデータ（ImageNet: 1400万枚の画像）
  2. GPU計算能力（並列行列演算に最適）
  3. アルゴリズムの改善（ReLU, BatchNorm, Dropout）

  主要アーキテクチャ:

  1. CNN（畳み込みニューラルネットワーク）:
     画像認識に特化
     ┌────────┐  ┌──────┐  ┌──────┐  ┌────┐
     │入力画像│→│畳み込み│→│プーリング│→│全結合│→ 分類
     │(HxWxC)│  │(特徴抽出)││(縮小) │  │    │
     └────────┘  └──────┘  └──────┘  └────┘

     畳み込みフィルタ:
     [1 0 -1]
     [1 0 -1]  → エッジ検出
     [1 0 -1]

     層が深くなるほど抽象的な特徴を学習:
     第1層: エッジ、色
     第2層: テクスチャ、パターン
     第3層: 部品（目、鼻、車輪）
     第4層: オブジェクト全体

  2. RNN / LSTM:
     系列データ（テキスト、音声、時系列）に特化

     ┌────┐  ┌────┐  ┌────┐  ┌────┐
     │ h₁ │→│ h₂ │→│ h₃ │→│ h₄ │→ 出力
     └──┬─┘  └──┬─┘  └──┬─┘  └──┬─┘
        ↑       ↑       ↑       ↑
       x₁      x₂      x₃      x₄
      (I)     (love)  (machine)(learning)

     LSTM: 長期依存性を学習（ゲート機構で勾配消失を防止）

  3. Transformer（2017, "Attention Is All You Need"）:
     自然言語処理の革命 → 現代AIの基盤

     Self-Attention:
     各トークンが文全体を参照して文脈を理解

     "The cat sat on the mat"
      ↑───────────────↑
      "cat"は"mat"に注意を向ける

     並列計算可能 → RNNより高速に学習
     → GPT, BERT, Claude, Gemini の基盤アーキテクチャ
```

---

## 6. 機械学習の実践フロー

```
MLプロジェクトのライフサイクル:

  1. 問題定義
     │ 「何を予測/分類するか」を明確化
     ▼
  2. データ収集・前処理
     │ 欠損値処理、正規化、特徴量エンジニアリング
     │ → データの質 = モデルの質（Garbage In, Garbage Out）
     ▼
  3. モデル選択・学習
     │ ベースライン → 複雑なモデルへ段階的に
     ▼
  4. 評価
     │ 訓練データとテストデータを分離して評価
     │
     │ 分類の評価指標:
     │ - 正解率(Accuracy): 全体の正答率
     │ - 適合率(Precision): 陽性予測のうち真陽性の割合
     │ - 再現率(Recall): 実際の陽性のうち検出できた割合
     │ - F1スコア: PrecisionとRecallの調和平均
     │
     │ 回帰の評価指標:
     │ - MSE: 平均二乗誤差
     │ - MAE: 平均絶対誤差
     │ - R²: 決定係数
     ▼
  5. デプロイ・監視
     モデルの劣化（データドリフト）を監視

過学習 vs 未学習:
  未学習           適切            過学習
  ──/──           ～S～           ～∿∿∿～
  訓練誤差:高     訓練誤差:低     訓練誤差:極低
  テスト誤差:高   テスト誤差:低   テスト誤差:高

  過学習対策:
  - データ増強（Data Augmentation）
  - 正則化（L1/L2, Dropout）
  - 早期打ち切り（Early Stopping）
  - 交差検証（Cross Validation）
```

---

## 7. 生成AI（Generative AI）

```
2022年〜: 生成AIの爆発的普及

  大規模言語モデル（LLM）:
  ┌──────────────────────────────────────────┐
  │ GPT系:  次のトークンを予測               │
  │ "The cat sat on the" → "mat"(確率最大)   │
  │                                          │
  │ パラメータ数の推移:                       │
  │ GPT-1 (2018):     1.17億                 │
  │ GPT-2 (2019):     15億                   │
  │ GPT-3 (2020):     1,750億                │
  │ GPT-4 (2023):     非公開（推定1兆以上）   │
  │ Claude 4.5(2025): 非公開                 │
  │                                          │
  │ スケーリング則:                           │
  │ モデルサイズ↑ + データ量↑ + 計算量↑       │
  │ → 予測精度が滑らかに向上                  │
  │ → 十分なスケールで「創発能力」が出現       │
  └──────────────────────────────────────────┘

  画像生成:
  - Stable Diffusion: テキスト→画像
  - DALL-E: テキスト→画像
  - Midjourney: 高品質アート生成

  動画生成:
  - Sora: テキスト→動画

  仕組み（拡散モデル / Diffusion Model）:
  ノイズを段階的に除去して画像を生成

  ノイズ → [denoise] → [denoise] → ... → 画像
  (ランダム)                              (鮮明)

  RAG（Retrieval-Augmented Generation）:
  外部知識を検索してLLMの回答を強化
  質問 → 関連文書検索 → LLMに文脈として提供 → 回答
  → ハルシネーション（捏造）の軽減
```

---

## 実践演習

### 演習1: [基礎] — 分類タスクの直感

```
以下のデータで「合格/不合格」を分類する決定木を手動で構築せよ:

| 勉強時間 | 睡眠時間 | 出席率 | 結果 |
|---------|---------|--------|------|
| 10      | 8       | 90%    | 合格 |
| 3       | 5       | 50%    | 不合格|
| 8       | 7       | 85%    | 合格 |
| 2       | 4       | 40%    | 不合格|
| 6       | 6       | 70%    | 合格 |
| 1       | 3       | 30%    | 不合格|

1. 最も有効な特徴量（分割基準）はどれか？
2. 決定木の深さはいくつになるか？
3. 新しいデータ（勉強5h, 睡眠6h, 出席60%）の予測は？
```

### 演習2: [応用] — 勾配降下法の手計算

```
線形回帰 y = wx + b で以下のデータを学習:

データ: (1, 2), (2, 4), (3, 6)
初期値: w=0, b=0, 学習率α=0.1

1. 初期予測値 ŷ を計算
2. MSE損失を計算
3. ∂L/∂w と ∂L/∂b を計算
4. パラメータを1回更新
5. 更新後の予測値と損失を計算

3回の更新でwとbがどう変化するか追跡せよ
```

### 演習3: [発展] — MLシステム設計

```
以下のMLシステムを設計せよ:

「ECサイトの商品レコメンデーションシステム」

要件:
- DAU 100万人
- 商品数 1000万点
- レスポンス 100ms以内

設計項目:
1. どのアルゴリズムを使うか（協調フィルタリング？コンテンツベース？）
2. 特徴量は何を使うか
3. オフライン学習 vs オンライン学習
4. キャッシュ戦略
5. A/Bテストの設計
6. データドリフトの監視方法
```

---

## FAQ

### Q1: プログラマにとって機械学習の知識はなぜ必要か？

現代のソフトウェア開発では、ML機能の統合が日常的になっている:
- 検索のランキング、レコメンデーション
- 不正検出、異常検知
- 自然言語処理（チャットボット、翻訳）
- コード補完（Copilot）
MLエンジニアでなくても、**MLの概念を理解し、適切に活用できるスキル**が求められる。

### Q2: 機械学習を始めるのに数学はどこまで必要か？

最低限必要な数学:
- **線形代数**: 行列演算（データの表現と変換）
- **微積分**: 偏微分（勾配降下法の理解）
- **確率統計**: 確率分布、ベイズの定理（モデルの評価）

ただし、実務ではscikit-learn、PyTorch、TensorFlowなどのライブラリが計算を抽象化しているため、**直感的な理解があれば始められる**。

### Q3: ChatGPTのような大規模言語モデルはどう学習されているか？

3段階のプロセス:
1. **事前学習（Pre-training）**: 大量のテキストで「次の単語の予測」を学習。数千GPU × 数ヶ月。
2. **ファインチューニング（SFT）**: 人間が作成した高品質な対話データで微調整。
3. **RLHF/RLAIF**: 人間/AIのフィードバックに基づく強化学習で、有用で安全な応答を学習。

---

## まとめ

| 概念 | ポイント |
|------|---------|
| 教師あり学習 | 入力+正解から学習。分類・回帰 |
| 教師なし学習 | 正解なしでパターン発見。クラスタリング・次元削減 |
| 強化学習 | 報酬を最大化する行動方策を学習 |
| ニューラルネット | 多層の非線形変換。逆伝播法で学習 |
| 深層学習 | CNN(画像), RNN(系列), Transformer(言語) |
| 生成AI | LLM, 拡散モデル。2022年〜急速に普及 |

---

## 次に読むべきガイド
→ [[02-blockchain-basics.md]] — ブロックチェーン入門

---

## 参考文献
1. Goodfellow, I. et al. "Deep Learning." MIT Press, 2016.
2. Bishop, C. M. "Pattern Recognition and Machine Learning." Springer, 2006.
3. Vaswani, A. et al. "Attention Is All You Need." NeurIPS, 2017.
4. Andrew Ng. "Machine Learning Yearning." 2018.
