# 分散システム

> 「分散システムとは、あるマシンの障害によって、あなたが存在すら知らなかった別のマシンが使えなくなるシステムのことである」——Leslie Lamport

## この章で学ぶこと

- [ ] 分散システムの基本概念と課題を理解する
- [ ] 一貫性モデルとコンセンサスアルゴリズムを説明できる
- [ ] 主要な分散アーキテクチャパターンを知る

---

## 1. なぜ分散システムが必要か

```
単一マシンの限界:

  CPU:     ムーアの法則の鈍化（2005年〜）
  メモリ:   1台のRAM上限（数TB）
  ストレージ: 1台のディスク上限（数十TB）
  可用性:   1台が落ちれば全停止

  → 複数マシンに分散して処理する必然性

分散システムの目的:
  1. スケーラビリティ: 処理能力の水平拡張
  2. 可用性:         一部の障害でもサービス継続
  3. レイテンシ:     ユーザーに近い場所で処理
  4. データ量:       1台に収まらないデータの管理

実例:
  Google検索:  数千台のサーバーが協調
  Netflix:     世界中のCDN + マイクロサービス群
  Bitcoin:     数万ノードが合意形成
```

---

## 2. 分散システムの8つの誤解

```
Peter Deutsch の「分散コンピューティングの8つの誤解」(1994):

  1. ネットワークは信頼できる        → パケットロス、切断は日常
  2. レイテンシはゼロである          → 光速の限界、ルーティング遅延
  3. 帯域幅は無限である             → ネットワーク飽和は起こる
  4. ネットワークは安全である        → 中間者攻撃、盗聴
  5. トポロジは変化しない           → サーバー追加/削除、障害
  6. 管理者は1人である             → 複数チーム、複数組織
  7. 転送コストはゼロである         → シリアライズ、暗号化のオーバーヘッド
  8. ネットワークは均一である        → 異なるハードウェア、OS、バージョン

  → これらを「当然」と思い込むと、分散システムは必ず壊れる
  → 設計段階から障害を前提にする必要がある
```

---

## 3. CAP定理と一貫性モデル

```
CAP定理（Eric Brewer, 2000）:
分散システムは以下の3つのうち、同時に2つしか保証できない

  C — Consistency（一貫性）:
      全ノードが同時に同じデータを見る
      → 書き込み直後に全ノードで最新値が読める

  A — Availability（可用性）:
      障害が起きていないノードは必ずレスポンスを返す
      → タイムアウトやエラーではなく、有効な応答

  P — Partition Tolerance（分断耐性）:
      ネットワーク分断が起きてもシステムが動作し続ける
      → ノード間の通信が途絶えても停止しない

  ┌─────────────────────────────────────────┐
  │         C (一貫性)                       │
  │        /\                                │
  │       /  \                               │
  │      /    \                              │
  │     / CP   \  CA                         │
  │    /  ↓     \ ↓                          │
  │   / Mongo    \ RDBMS                     │
  │  /  HBase     \(単一ノード)              │
  │ /──────────────\                         │
  │ A (可用性)  P (分断耐性)                  │
  │       AP ↓                               │
  │    Cassandra, DynamoDB                   │
  └─────────────────────────────────────────┘

  現実: ネットワーク分断は避けられない → P は必須
  → 実質 CP か AP の二択

CP（一貫性優先）:
  分断時 → 一部のリクエストにエラーを返す
  用途: 銀行送金、在庫管理、座席予約
  例: MongoDB(デフォルト), ZooKeeper, etcd, HBase

AP（可用性優先）:
  分断時 → 古いデータを返す可能性があるが応答はする
  用途: SNSタイムライン、いいね数、ショッピングカート
  例: Cassandra, DynamoDB, CouchDB, Riak
```

### 一貫性モデルの詳細

```
一貫性の強さ（強い順）:

  1. 線形化可能性（Linearizability）:
     → 全操作がグローバルな順序で実行されたかのように見える
     → 最も強い保証、最もコストが高い
     → 例: ZooKeeper, etcd

  2. 逐次一貫性（Sequential Consistency）:
     → 各プロセスの操作順序は保持
     → プロセス間の順序は保証しない

  3. 因果一貫性（Causal Consistency）:
     → 因果関係のある操作の順序は保持
     → 因果関係のない操作は任意の順序
     → 例: MongoDB(デフォルト)

  4. 結果整合性（Eventual Consistency）:
     → 十分な時間が経てば全ノードが一致
     → 途中では古いデータが読める
     → 例: DynamoDB, Cassandra, DNS

  強い ←──────────────────────→ 弱い
  線形化  逐次  因果  結果整合
  遅い  ──────────────────── 速い
  高コスト ────────────── 低コスト
```

---

## 4. コンセンサスアルゴリズム

```
コンセンサス問題:
  複数のノードが1つの値に合意する

  なぜ難しいか:
  - ノードが故障する可能性
  - メッセージが遅延・消失する可能性
  - ネットワークが分断する可能性
  - ビザンチン障害（悪意あるノード）の可能性

FLP不可能性定理（1985）:
  非同期ネットワークで1台でも故障する可能性がある場合、
  決定的なコンセンサスは不可能
  → 実用的には確率的手法やタイムアウトで回避
```

### Paxos

```
Paxos（Leslie Lamport, 1989/1998）:

  役割:
  - Proposer: 提案を出す
  - Acceptor: 提案を受け入れる/拒否する
  - Learner:  合意結果を学習する

  2フェーズプロトコル:

  Phase 1 (Prepare):
  Proposer          Acceptor (過半数)
     │── Prepare(n) ──→│
     │←── Promise(n) ──│  「n以上の提案にしか応答しない」

  Phase 2 (Accept):
     │── Accept(n,v) ──→│
     │←── Accepted ────│  過半数がAcceptすれば合意成立

  特徴:
  - 理論的に正しいが実装が非常に難しい
  - Lamportの原論文は「パート・タイム議会」として書かれ、
    分かりにくいことで有名
  - Google Chubby (2006) で実用化
```

### Raft

```
Raft（Diego Ongaro, 2014）:
  「理解しやすいコンセンサス」を目標に設計

  役割（3種類のみ）:
  - Leader:    全ての書き込みを処理
  - Follower:  Leaderの指示に従う
  - Candidate: Leader選挙に立候補中

  3つのサブ問題に分解:

  1. リーダー選出:
     ┌──────────────────────────────────────┐
     │ Follower → (タイムアウト) → Candidate │
     │ Candidate → (過半数投票) → Leader     │
     │ Leader → (ハートビート) → 維持        │
     │ Leader → (障害) → Follower → ...      │
     └──────────────────────────────────────┘

     任期(Term)ごとにLeaderは最大1人
     Term番号が大きい方が新しい

  2. ログ複製:
     Client → Leader → Follower群に複製
     過半数が書き込み完了 → コミット

     Leader   [1][2][3][4][5]
     Follow-A [1][2][3][4][5]  ← 同期済み
     Follow-B [1][2][3]        ← 遅延（後で追いつく）
     Follow-C [1][2][3][4]     ← 1つ遅延

  3. 安全性:
     - コミット済みのエントリは上書きされない
     - 最も新しいログを持つノードのみLeaderになれる

  実装例:
  - etcd (Kubernetes の基盤)
  - HashiCorp Consul
  - CockroachDB
  - TiKV (TiDB の基盤)
```

---

## 5. 分散データストア

```
データ分散の2つの軸:

  1. レプリケーション（複製）:
     同じデータを複数ノードに複製
     → 可用性向上、読み取りスケール

     方式:
     ┌──────────────────────────────────────────┐
     │ 同期レプリケーション:                      │
     │   Master ──→ Slave1 (ACK待ち)             │
     │         ──→ Slave2 (ACK待ち)              │
     │   → 強い一貫性、書き込み遅い               │
     │                                            │
     │ 非同期レプリケーション:                     │
     │   Master ──→ Slave1 (ACK待たない)          │
     │         ──→ Slave2 (ACK待たない)           │
     │   → 弱い一貫性、書き込み速い               │
     │                                            │
     │ 準同期(Semi-sync):                         │
     │   Master ──→ Slave1 (ACK待ち)             │
     │         ──→ Slave2 (ACK待たない)           │
     │   → バランス型。MySQL の推奨設定            │
     └──────────────────────────────────────────┘

  2. パーティショニング/シャーディング（分割）:
     データを複数ノードに分割配置
     → 容量・書き込みスケール

     分割方式:
     ┌──────────────────────────────────────────┐
     │ 範囲分割（Range Partitioning）:            │
     │   Shard1: A-G, Shard2: H-N, Shard3: O-Z  │
     │   → 範囲クエリが効率的                     │
     │   → ホットスポットが発生しやすい            │
     │                                            │
     │ ハッシュ分割（Hash Partitioning）:          │
     │   Shard = hash(key) % N                    │
     │   → 均等に分散                             │
     │   → 範囲クエリが非効率                     │
     │                                            │
     │ コンシステントハッシュ:                     │
     │   ノード追加/削除時に最小限の再配置         │
     │   → DynamoDB, Cassandra が採用             │
     └──────────────────────────────────────────┘
```

### コンシステントハッシュの仕組み

```
従来のハッシュ: hash(key) % N
  → ノード数Nが変わると全データの再配置が必要

コンシステントハッシュ:
  ハッシュ空間を円（リング）として扱う

       0°
       │
  270°─┼─90°    ← ハッシュリング
       │
      180°

  ノードをリング上に配置:
       Node-A (30°)
      ╱
  ───●─────●─── Node-B (120°)
     │     │
     │     │
  ───●─────●─── Node-C (210°)
            ╲
             Node-D (300°)

  キーのハッシュ値からリング上を時計回りに探索し、
  最初に見つかるノードに格納

  ノード追加時: 隣接ノードのデータの一部だけ移動
  ノード削除時: 隣接ノードにデータが引き継がれる
  → 影響範囲が 1/N に限定される

  仮想ノード（Virtual Node）:
  1つの物理ノードに複数の仮想ノードを割り当て
  → 負荷の偏りを軽減
```

---

## 6. 分散トランザクション

```
単一DBのACID:
  A(Atomicity): 全て成功 or 全て失敗
  C(Consistency): 制約を常に満たす
  I(Isolation): 並行トランザクションが干渉しない
  D(Durability): コミットしたら永続化

分散環境のACID → 非常に困難

2フェーズコミット（2PC）:

  Coordinator         Participant A    Participant B
       │── Prepare ──→│               │
       │── Prepare ──────────────────→│
       │←── Yes ──────│               │
       │←── Yes ──────────────────────│
       │── Commit ───→│               │
       │── Commit ────────────────────→│
       │←── ACK ──────│               │
       │←── ACK ──────────────────────│

  問題:
  - Coordinatorがフェーズ2で障害 → 全体ブロック
  - 参加者は「準備完了」後、結果を知るまでロック保持
  - パフォーマンス低下（同期的待ち合わせ）

Sagaパターン（代替手法）:

  分散トランザクションを一連のローカルトランザクションに分解

  T1 → T2 → T3 → 成功

  T1 → T2 → T3(失敗) → C3 → C2 → C1
  （Cは補償トランザクション = 取り消し操作）

  例: ECサイトの注文処理
  T1: 在庫を確保        C1: 在庫を戻す
  T2: 決済を実行        C2: 返金する
  T3: 配送を手配        C3: 配送をキャンセル

  オーケストレーション型:
    中央のSagaオーケストレータが制御

  コレオグラフィー型:
    各サービスがイベントを発行して連鎖
```

---

## 7. 時間と順序

```
分散システムにおける「時間」の問題:

  物理時計の問題:
  - クロックスキュー: マシン間で時刻がずれる
  - クロックドリフト: 時計の進み方が微妙に異なる
  - NTPの精度: 数ms〜数十msの誤差
  → 物理時計だけでイベントの順序を決めるのは危険

論理時計（Lamport Clock, 1978）:

  ルール:
  1. 内部イベント: カウンタ++
  2. 送信時: カウンタ++, メッセージにカウンタを付与
  3. 受信時: max(自分, 受信値) + 1

  Process A:  1 ──→ 2 ──────→ 5
                     │ send    ↑ recv
  Process B:       3 ──→ 4 ──→│
                               │ send
  Process C:            2 ──→ 5 ──→ 6

  因果関係: a → b なら L(a) < L(b)
  逆は不成立: L(a) < L(b) でも a → b とは限らない

ベクトル時計（Vector Clock）:

  各プロセスが全プロセスのカウンタを保持
  → 因果関係を完全に判定できる

  [A:1, B:0, C:0]  と [A:0, B:1, C:0]
  → 全要素で ≤ でない → 並行（因果関係なし）

  [A:1, B:0, C:0]  と [A:2, B:1, C:0]
  → 前者が因果的に先行

  用途: DynamoDB の競合検出
```

---

## 8. 分散アーキテクチャパターン

```
1. マイクロサービス:
   モノリス → 独立したサービスに分割

   ┌──────────┐  ┌──────────┐  ┌──────────┐
   │ User     │  │ Order    │  │ Payment  │
   │ Service  │  │ Service  │  │ Service  │
   │ (Go)     │  │ (Java)   │  │ (Python) │
   └────┬─────┘  └────┬─────┘  └────┬─────┘
        │              │              │
   ┌────┴──────────────┴──────────────┴────┐
   │         Message Bus (Kafka)            │
   └───────────────────────────────────────┘

   利点: 独立デプロイ、技術選択の自由、障害の局所化
   課題: ネットワーク遅延、データ整合性、運用複雑性

2. イベント駆動アーキテクチャ:
   サービス間をイベントで疎結合

   Producer → Event Bus → Consumer A
                        → Consumer B
                        → Consumer C

   Event Sourcing:
   状態の変化をイベントとして記録
   [Created] → [Updated] → [Shipped] → [Delivered]
   → イベントの再生で任意の時点の状態を再現可能

3. CQRS（Command Query Responsibility Segregation）:
   書き込み（Command）と読み取り（Query）を分離

   Write Model          Read Model
   ┌──────────┐        ┌──────────┐
   │ Command  │──Event→│ Query    │
   │ Store    │        │ Store    │
   │ (正規化) │        │ (非正規化)│
   └──────────┘        └──────────┘
       ↑ write              ↑ read
       │                    │
   Commands             Queries

   → 書き込みと読み取りを独立にスケール
   → 読み取りモデルを用途に最適化できる
```

---

## 9. 障害とリカバリ

```
障害の種類:

  1. クラッシュ障害: ノードが停止
     → 検出: ハートビート + タイムアウト
     → 対策: レプリカへのフェイルオーバー

  2. ネットワーク障害: 通信途絶
     → 検出: タイムアウト（クラッシュと区別困難）
     → 対策: リトライ + 冪等性

  3. ビザンチン障害: 悪意ある動作
     → 検出: 暗号学的証明（署名、ハッシュ）
     → 対策: BFTアルゴリズム（ノードの1/3未満なら耐える）

  4. 灰色障害: 部分的な障害
     → ネットワーク遅延の増大、パケットの一部消失
     → 最も検出が難しい

障害対策パターン:

  Circuit Breaker:
  ┌─────────┐    ┌──────────┐    ┌──────────┐
  │ Closed  │───→│  Open    │───→│Half-Open │
  │(正常通過)│ 失敗│(即座に   │ 一定│(テスト   │
  │         │ 閾値│ エラー)  │ 時間│ リクエスト)│
  └─────────┘ 超過└──────────┘ 経過└─────┬────┘
       ↑                              │
       └──────── 成功 ────────────────┘

  Bulkhead（隔壁）:
  障害の影響範囲を限定
  → サービスAの障害がサービスBに波及しない

  Retry with Exponential Backoff:
  1回目: 100ms後
  2回目: 200ms後
  3回目: 400ms後
  + ジッター（ランダムな揺らぎ）で雷鳴問題を回避
```

---

## 実践演習

### 演習1: [基礎] — CAP定理の適用

```
以下のシステムでCP/APどちらを選ぶべきか、理由とともに答えよ:

1. オンライン銀行の残高照会
2. Twitterのフォロワー数表示
3. 航空券の座席予約
4. ニュースサイトのコメント欄
5. 分散ロック（リーダー選出）

ヒント: 「一貫性が崩れた場合の最悪のシナリオ」を考える
```

### 演習2: [応用] — Raftのシミュレーション

```
5ノードのRaftクラスタで以下の状況をシミュレートせよ:

初期状態: Node1がLeader (Term 3)
1. Node1にネットワーク障害が発生
2. Node2, Node3, Node4, Node5 の中から新Leaderが選出される過程を追跡
3. 旧Leader(Node1)がネットワーク復帰した場合の動作

各ステップで:
- 各ノードの状態（Leader/Follower/Candidate）
- Term番号
- 投票の流れ
を書き出すこと
```

### 演習3: [発展] — 分散KVストアの設計

```
以下の要件を満たす分散Key-Valueストアを設計せよ:

要件:
- 3ノード構成（レプリケーションファクター = 3）
- GET/PUTの2操作
- 結果整合性
- ノード1台の障害に耐える

設計項目:
1. データの配置方式（コンシステントハッシュ）
2. 書き込みのレプリケーション方式
3. 読み取り時の整合性保証（Quorum: W + R > N）
4. 障害検出と復旧の仕組み

W=2, R=2, N=3 の場合のシナリオを具体的に記述すること
```

---

## FAQ

### Q1: マイクロサービスはいつ採用すべきか？

最初からマイクロサービスにするのは**アンチパターン**（Martin Fowler: "MonolithFirst"）。まずモノリスで始め、以下の条件が揃ったら分割を検討する:
- チームが10人以上でコードの競合が頻発
- 一部の機能だけスケールしたい
- 異なる技術スタックが必要な部分がある
- デプロイ頻度を独立させたい

### Q2: 結果整合性はどれくらいの「遅延」があるのか？

システムと設定によるが、典型的には:
- DynamoDB: 通常1秒未満（ほぼ瞬時）
- Cassandra: ミリ秒〜数秒
- DNS: TTL依存（数分〜数時間）
- S3: 2020年以降は即座に強い一貫性を提供

重要なのは「遅延の長さ」ではなく「遅延がある前提でシステムを設計すること」。

### Q3: CAP定理は古いのか？

CAP定理は依然として有効だが、過度に単純化されている面がある。PACELC定理がより現実的:
- **分断時(P)**: AvailabilityかConsistencyを選択
- **通常時(E)**: LatencyかConsistencyを選択

実際のシステムは「CP or AP」の二択ではなく、操作ごとに一貫性レベルを調整する（例: DynamoDBの強い一貫性読み取り）。

---

## まとめ

| 概念 | ポイント |
|------|---------|
| CAP定理 | P は必須。実質 CP(一貫性) vs AP(可用性)の選択 |
| コンセンサス | Paxos(理論), Raft(実用)。過半数の合意で決定 |
| レプリケーション | 同期(強一貫性) vs 非同期(高性能) |
| シャーディング | コンシステントハッシュで最小限の再配置 |
| 障害対策 | Circuit Breaker, Bulkhead, Exponential Backoff |
| 時間 | 物理時計は信頼不可。論理時計/ベクトル時計を使用 |

---

## 次に読むべきガイド
→ [[01-machine-learning-basics.md]] — 機械学習入門

---

## 参考文献
1. Kleppmann, M. "Designing Data-Intensive Applications." O'Reilly, 2017.
2. Lamport, L. "Time, Clocks, and the Ordering of Events in a Distributed System." 1978.
3. Ongaro, D. & Ousterhout, J. "In Search of an Understandable Consensus Algorithm (Raft)." 2014.
4. Brewer, E. "CAP Twelve Years Later." IEEE Computer, 2012.
5. Deutsch, P. "The Eight Fallacies of Distributed Computing." 1994.
